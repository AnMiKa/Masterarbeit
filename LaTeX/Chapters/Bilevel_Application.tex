\section{Application to Model Selection for Primal SVM}
\label{sec_bilevel}

%\textcolor{red}{Skalarprodukt anpassen, Vektoren nicht fett oder neue definition, notation, \(\lambda \in \Lambda\) einfugen\\
%Vektoren (in gesamter Arbeit) in runden Klammern}

\subsection{Introduction}

In this part of the thesis the nonconvex inexact bundle algorithms \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1 are applied to the problem of model selection for \emph{support vector machines} (SVMs) solving classification tasks.
It relies on a bilevel formulation proposed by Kunapuli in \cite{Kunapuli2008} and Moore et al. in \cite{Moore2011}.

A natural application for the inexact bundle algorithm is an optimization problem where the objective function value and the subgradient can only be computed by numerical approximation. This is for example the case in bilevel optimization.
%If this objective function is iteratively optimized, the function value i never exact. But by the stopping condition it is (often???) possible to have the needed error bound on the function value (what about the gradient???). (Comment on asymptotical exactness?)

%A general bilevel problem can be formulated as 
%Bilevel optimization deals with a class of constrained optimization problems where one or more of the optimization variables are again constrained by optimization problems.
A general bilevel program can be formulated as in \cite[p. 20]{Kunapuli2008}

\begin{equation}
	\begin{array}{cll}
	\displaystyle\min_{C \in U_{ad}, \tilde{w} \in \R^k} & \mathcal{L}_{upp}(C,\tilde{w}) & \text{upper level} \vspace{0.5ex}\\
	\text{s.t.} & \mathcal{G}_{upp}(C,\tilde{w}) \leq 0 & \vspace{1em}\\
	& \tilde{w} \in \begin{Bmatrix} \displaystyle\argmax_{\tilde{w}\in W} & \mathcal{L}_{low}(C,\tilde{w}) \vspace{0.5ex}\\
	                        \text{s.t.} & \mathcal{G}_{low}(C,\tilde{w}) \leq 0 
													\end{Bmatrix}. & \text{lower level}
	\end{array}
	\label{bilevel}
\end{equation}

The two objective functions \(\mathcal{L}_{upp}\) and \(\mathcal{L}_{low}\) map from \(\R^n\times\R^k\) into \(\R\) and the constraint functions \(\mathcal{G}_{upp}\) and \(\mathcal{G}_{low}\) map from \(\R^n\times\R^k\) into \(\R^l\) and \(\R^s\) respectively. 

The problem consists of an \emph{upper} or \emph{outer level} which is the overall function to be optimized. Contrary to usual constrained optimization problems which are constrained by explicitly given equalities and inequalities, a  bilevel program is additionally constrained by a second optimization problem, the \emph{lower} or \emph{inner level} problem.

Solving bilevel problems can be divided roughly in two classes: implicit and explicit solution methods. 
In the explicit methods the lower level problem is usually rewritten by its KKT conditions, these are then added as constraints to the upper level problem. Using this solution method the upper and lower level are solved simultaneously. For the setting of model selection for support vector machines as it is used here, this method is described in detail in \cite{Kunapuli2008}.

The second approach is the implicit one. Here the lower level problem is solved directly in every iteration of the outer optimization algorithm and the solution is plugged into the upper level objective. 

Obviously if the inner level problem is solved numerically, the solution cannot be exact. Additionally the \emph{solution map} \( S(C) = \{w\in \R^k \mid w\) solves the lower level problem for a given \(C\}\), can be nondifferentiable \cite{Outrata1998} and since elements of  the solution map are plugged into the outer level objective function in the implicit approach, the outer level function then becomes nonsmooth itself. This is why the inexact bundle algorithm seems a natural choice to tackle these bilevel problems. 

Moore et al. use the implicit approach in \cite{Moore2011} for support vector regression. However they use a gradient descent method which is not guaranteed to stop at an optimal solution.
In \cite{Moore2010a} it is suggested to use the nonconvex exact bundle algorithm of Fuduli et al. \cite{Fuduli2004a} for solving the bilevel regression problem. This method allows for nonsmooth inner problems and can theoretically solve some of the issues of the gradient descent method. It ignores however, that the objective function values can only be calculated approximately; a fact which is not addressed in Fuduli's algorithm.

%\subsection{Notation and Expressions}

%training set, validation /holdout set...

\subsection{Notation}

A short remark on the notation in this chapter is required.

Due to standard notation in the field of SVM, the variables \(x\) and \(y\) are used in this chapter in a different manner than before.
%In the setting of bilevel problems as used in (\ref{bilevel}) \(x \in X \subset \R^n\) and \(y \in \R^k\) are the optimization variables of the bilevel problem.

In the setting of SVMs \(x^i \in \R^{n_f}\) is an element of the \emph{feature space} that contains the values of one data point. The corresponding variable \(y_i \in \{-1,1\}\) of the \emph{output domain} contains the class in which the data point \(x^i\) lies. Sometimes the indices of the samples are omitted to express the general dependency on the data (x,y).
%All samples can be wrapped up in a martix \(X \in \R^{feat\times nd}\) and a vector \(Y\in \R^{nd}\).
The optimization variable of the bundle method is denoted by \(C\) during this chapter.

%During the most part of the chapter, \(x^i\) and \(y^i\) are used as in the context of SVMs. In the cases where they are used to describe the variables of an optimization problem, this is clearly indicated.

In this chapter there appear also different derivatives.
For a continuously differentiable function \(f:\R^n \times \R^k \to \R\) we denote the \emph{gradient} at \((\bar{C},\bar{\tilde{w}})\) by \(\nabla f(\bar{C},\bar{\tilde{w}}) \in \R^{n+k}\). The partial gradient with respect to \(\tilde{w}\) is indicated by \(\nabla_{\tilde{w}}f(\bar{C},\bar{\tilde{w}}) \in \R^k \). %If \(f\) is twice continuously differentiable the \emph{Hessian matrix} at the point \((\bar{x},\bar{y})\) is given by \(\nabla^2 f(\bar{x},\bar{y}) \in \R^{n+m \times n+m}\).
For a continuously differentiable vector valued function \(F:\R^n \times \R^k \to \R^m\) the \emph{Jacobian matrix} is given by \( \mathcal{J}F(\bar{C},\bar{\tilde{w}}) \in \R^{m \times (n+k)}\). The partial Jacobian with respect to the variable \(\tilde{w}\) is denoted \(\mathcal{J}_{\tilde{w}} F(\bar{C},\bar{\tilde{w}}) \in \R^{m \times k}\).

Finally let \(M \in \R^{n\times k}\) be a matrix and \(I \subset \{1,...,n\}\) an index set. Then the expression \(M_{I}\) denotes the matrix that consists of the rows of \(M\) corresponding to the indices in the set \(I\). %For a vector \(v \in \R^n\) the vector \(v_{I}\) consists of the components of \(v\) corresponding to the set \(I\).

%special notation only in this chapter, \(x,y\) now different. Optimization variable now \(\lambda,C\).
%with index -> data, without variables from problem.
%Will be clear from context.
%
%do this due to the standard notation in the field of SVM

\subsection{Introduction to Support Vector Machines}
%In times of big data machine learning is a very active field of research. 
Support vector machines are linear learning machines that were developed in the 1990's by Vapnik and co-workers (see \cite{Boser1992}, where SWMs were introduced). Soon they could outperform several other programs in this area \cite{Cristianini2000} and the subsequent interest in SVMs led to a very versatile application of these machines \cite{Kunapuli2008}.

The case that is considered here is binary support vector classification using supervised learning. 
For a thorough introduction to this subject see also \cite{Cristianini2000}. Here a summary of the most important expressions and results is given.

In classification data from a possibly high dimensional vector space \(\tilde{X} \subset \R^{n_f}\), the feature or \emph{input space} is divided into two classes. These lie in the output domain \(\tilde{Y} = \{-1,1\}\). Elements from the feature space will mostly be called \emph{data points} here. They get \emph{labels} from the feature space. Labeled data points are called \emph{examples}.
The functional relation between the features and the class of an example is given by the usually unknown \emph{response} or \emph{target function} \(f(x)\).
Supervised learning is a kind of machine learning task where the machine is given examples of input data with associated labels, the so called \emph{training data} \((X,Y)\). Mathematically this can be modeled by assuming that the examples are  drawn \emph{identically and independently distributed} (iid) from the fixed joint distribution \(P(x,y)\). This usually unknown distribution states the probability that a data point \(x\) has the label \(y\) \cite[p. 988]{Vapnik1999}.
The overall goal is then to optimize the generalization ability, meaning the ability to predict the output for unseen data correctly \cite[chapter 1.2]{Cristianini2000}.
%The overall goal of machine learning is to optimize the generalization ability of the algorithm --> this means: predict output for unlabeled input as well as possible.
%task is to find a mapping that predicts the output given unlabeled input as good as possible \cite{Cristianini2000}. 

\subsubsection{Risk minimization}
The concept of SVMs was originally inspired by the statistical learning theory developed by Vapnik. A detailed examination of the subject is given in \cite{Vapnik1998}. In \cite{Vapnik2013} the subject is approached from a more explaining point of view.

%from: Vapnik - Statistical Learning Theory overview \cite{Vapnik1998}
The idea of \emph{risk minimization} is to find from a fixed set or class of functions the one that is the best approximation to the response function. This is done by minimizing a loss function that compares the given labels of the examples to the response of the learning machine.
%goal: find best available (from set of functions that was chosen before) approximation to the actual (unknown) ``response function'' --> function that ``classifies'' the data
%Minimize loss between response of ``supervisor'' and response of learning machine

As the response function is not known, only the expected value of the loss can be calculated. It is given by the \emph{risk functional} 

\begin{equation}
	R(\lambda) = \int{\mathcal{L}(y,f_{\lambda}(x))\text{d}P(x,y)}.
\label{risk_func}
\end{equation}

Here \(\mathcal{L}: \R^2 \to \R\) is the loss function, \(f_{\lambda}: \R^{n_f} \to \R, ~ \lambda \in \Lambda\) the approximate response function found by the learning machine and \(P(x,y)\) the joint distribution the training data is drawn from. The goal is now to find a function \(f_{\bar{\lambda}}(x)\) in a chosen function space \(\mathcal{F}\) that minimizes this risk functional \cite[p. 989]{Vapnik1999}.

As the only given information is provided by the training set inductive principles are used to work with the \emph{empirical risk}, rather than with the risk functional.
The empirical risk only depends on the finite training set  and is given by 

%goal: find \(f_{\lambda_0}(x)\) that minimizes this functional
%\(P(x,y)\) is unknown
%Because only a data sample is known: Work with the empirical risk

\begin{equation}
	R_{\text{emp}}(\lambda) = \frac{1}{n_d} \sum_{i = 1}^{n_d}\mathcal{L}(y_i,f_{\lambda}(x^i)),
\label{emp_risk}
\end{equation}

where \(n_d\) is the number of data points.
%L: Loss function 
%Goal: approximate \(Q(z,\lambda_0)\) by \(Q(z,\lambda_l)\) that minimizes the empirical risk. --> is called ERM (empirical risk minimization induction principle)
The law of large numbers ensures that the empirical risk converges to the risk functional as the number of data points grows to infinity. This however does not guarantee that the function \(f_{\bar{\lambda},\text{emp}}\) that minimizes the empirical risk also converges towards the function \(f_{\bar{\lambda}}\) that minimizes the risk functional.
The theory of consistency provides necessary and sufficient conditions that solve this issue  \cite[p. 989]{Vapnik1999}.

Vapnik therefore introduced the structural risk minimization (SRM) induction principle. It ensures that the used set of functions has a structure that makes it strongly consistent \cite{Vapnik1999}. Additionally it takes the complexity of the function that is used to approximate the target function into account. ``The SRM principle actually suggests a tradeoff between the quality of the approximation and the complexity of the approximating function'' \cite[p. 994]{Vapnik1999}.
This reduces the risk of \emph{overfitting}, meaning to overly fit the function to the training data with the result of poor generalization \cite[chapter 1.3]{Cristianini2000}.

%Therefore: structural risk Minimization induction Principle (SRM) --> is strongly consistent --> idea: minimize the empirical risk by considering the complexity of the model (given by CV-dimension)

Support vector machines fulfill all conditions of the SRM principle. Due to the kernel trick that allows for nonlinear classification tasks it is also very powerful. For more detailed information on this see \cite{Kunapuli2008} and references therein.

\subsubsection{Support Vector Machines}
\label{sec_SVMs}

In the case of linear binary classification one searches for an affine hyperplane \(w \in \R^{n_f}\) shifted by \(b \in \R\) to separate the given data. The vector \(w\) is called weight vector and \(b\) is the bias.

Let the data be linearly separable. This means, that there exists an affine hyperplane \((w,b)\) such that all data points from one class are on the same side of the hyperplane. The function deciding how the data is classified can be written as

\[ f(x) = \text{sign}(\Langle w,x\Rangle-b). \]

Support vector machines aim at finding such a hyperplane that separates also unseen data optimally.


One problem of this approach is that the representation of a hyperplane is not unique. If the plane described by \((w,b)\) separates the data, there exist infinitely many hyperplanes \((tw,b)\), \(t>0\), that separate the data in the same way.
To have a unique description of a separating hyperplane the \emph{canonical hyperplane for given data} \(x \in X\) is defined by
 
\[ f(x) = \Langle w, x\Rangle - b  \quad \text{s.t.} \quad \min_i \left\vert\Langle w,x^i\Rangle -b\right\vert = 1.\] 

To find such a hyperplane is always possible in the case where the data is  linearly separable. It means that the inverse of the norm of the weight vector is equal to the distance of the closest point \(x \in X \) to  the hyperplane \cite[p. 10]{Kunapuli2008}.


%Kunapuli: representation of hyperplane not unique --> if \((w,b)\) separates data, infinitely many hyperplanes \((tw,tb) \forall t > 0\) also separate data --> need unique representation --> w.l.o.g. define \emph{canonical hyperplane} for given data \(x \in X\) as function 
%only valid for separable data

This gives rise to the following definition:
The \emph{margin} is the minimal Euclidean distance between a training example \(x^i\) and the separating hyperplane.
%one can show that margin invese proportional to norm of \(w\).
A bigger margin means a lower complexity of the function \cite{Cristianini2000}. It is additionally shown in \cite[p. 10]{Kunapuli2008} that the margin is proportional to the inverse of \(\Vert w \Vert\).

A \emph{maximal margin hyperplane} is the hyperplane that realizes the maximal possible margin for a given data set.

%Theorem 6.1
\begin{proposition}[{\cite[Proposition 6.1]{Cristianini2000}}]
Given a linearly separable training sample \ \(\Omega = \{(x^1,y_1),...,(x^{n_d},y_{n_d})\}\) the hyperplane \((w,b)\) that solves the optimization problem

\[\|w\|^2 \quad \text{s.t.} \quad y_i\left(\Langle w,x^i\Rangle-b\right)\geq 1, \quad i = 1,...,n_d, \]

realizes a maximal margin hyperplane.
\end{proposition}

The proof is given in \cite[chapter 6.1]{Cristianini2000}. 

%\textcolor{red}{???Picture of hyperplane}
\begin{figure}[ht]%
	\center
	\input{Pictures/TikZ/hyperplane}%
\caption[Separating hyperplane]{A separating hyperplane \(w\) with bias \(b\). The dashed lines above and below the plane indicate the margin.}%
\label{fig_hyperplane}%
\end{figure}

Generally one cannot assume the data to be linearly separable. This is why in most applications a so called \emph{soft margin classifier} is used. It introduces the slack variables \(\xi_i\) that measure the distance of the misclassified points to the hyperplane:

%from this follows: soft margin classifyer --> not any more assumption that data linearly separable --> slack variables \(\xi_i\) measure the distance of misclassified points

%Def 2.6:
%\begin{definition} \cite{Cristianini2000}
Fix \(\gamma > 0\). A \emph{margin slack variable of the example} \((x^i,y_i)\) with respect to the hyperplane \((w,b)\) and target margin \(\gamma\) is 

\[\xi_i = \max\left\{0, \gamma - y_i\left(\Langle w,x^i\Rangle+b\right)\right\}\] 

%\end{definition}  
If \(\xi_i > \gamma\) the point is considered misclassified. 
One can also say that \(\|\xi\|\) ``measures the amount by which the training set fails to have margin \(\gamma\)'' \cite[section 2.1.1]{Cristianini2000}.

For support vector machines the target margin is set to \(\gamma = 1\).

%Book uses \(\xi^2\) -> then \(\xi>0\) not needed any more; only \(\xi\) also used -> 1-norm
%This results finally in the following slightly different
%optimization problems for finding an optimal separating hyperplane \((w,b)\):

This results in the following optimization problem for finding an optimal separating hyperplane \((w,b)\): 


%and
%
\begin{align}
\begin{split}
	\min_{w,b,\xi} \quad & \frac{1}{2} \|w\|^2_2+\frac{C}{2}\sum_{i=1}^{n_d}{\xi_i^2} \vspace{0.5ex}\\
	\text{s.t.} \quad & y_i\left(\Langle w,x^i\Rangle-b\right) \geq 1 - \xi_i \vspace{0.5ex}\\
	& 	\forall i = 1, \dots , n_d.
\end{split}
\label{SVM_2}
\end{align}

%The first part of the respective objective functions are the regularizations, the second part are the actual loss functions.
The first part of the objective function is the regularization, the second part the actual loss function. 
The parameter \(C > 0\) gives a trade-off between the richness of the chosen set of functions \(f_{\lambda}\) to reduce the error on the training data and the danger of overfitting to have good generalization. It has to be chosen a priori \cite{Kunapuli2008}.
%The two optimization problems only differ in the norm chosen for the loss function. In (\ref{SVM_1}) the one-norm is chosen, in (\ref{SVM_2}) the squared two-norm is used.

Instead of the Euclidean norm it is also possible to use the 1-norm in the loss function. Then the resulting optimization problem reads:

\begin{align}
\begin{split}
	\min_{w,b,\xi} \quad & \frac{1}{2} \|w\|^2+C\sum_{i=1}^{n_d}{\xi_i} \\
	\text{s.t.} \quad & y_i\left(\Langle w,x^i\Rangle-b\right) \geq 1 - \xi_i \\
	& \xi_i \geq 0 \\
	& 	\forall i = 1, \dots , n_d.
\end{split}
\label{SVM_1}
\end{align}

In this form, however, the problem does not fit the theory described in \cite{Outrata1998}, which is used later to solve the constructed bilevel problem. In Appendix \ref{sec_counter_ex} it is shown, that for some data sets the strong regularity condition (a crucial concept introduced in section \ref{sec_str_reg} of this thesis) may not hold in some solutions of this problem. Thus the subgradient of the upper level objective function cannot be calculated as proposed in \cite{Outrata1998}.


%To derive a subgradient of the bilevel problem introduced later in this section another formulation of the classification problem is used.
In order to fulfill all conditions assumed in \cite{Outrata1998} it is necessary to reformulate problem (\ref{SVM_2}).
The new formulation makes use of the \emph{implicit bias}, meaning that the bias is not calculated separately but as part of the variable \(w\). 
By adding an additional '1' to the end of each feature vector we can use the vectors \(\tilde{x}_i := (x_i^{\top},1)^{\top}\) and \(\tilde{w} := (w^{\top},w_b)^{\top}\) to state the following optimization problem:

\begin{equation}
\begin{split}
	\min_{\tilde{w},\xi} \quad & \frac{1}{2} \|\tilde{w}\|^2+\frac{C}{2}\sum_{i=1}^{n_d}{\xi_i^2} \vspace{0.5ex}\\
	\text{s.t.} \quad & y_i\Langle \tilde{w},\tilde{x}^i\Rangle = y_i\left(\Langle w,x^i\Rangle-w_b\right) \geq 1 - \xi_i \vspace{0.5ex}\\
	& 	\forall i = 1, \dots , n_d.
\label{SVM_bias}
\end{split}
\end{equation}

Not treating the bias separately is a strategy used for example to achieve a more efficient implementation \cite[section 3.2, p. 22]{Gunn1998}. In the course of this section the gain of this particular formulation is the fact that it has a unique solution for every \(C > 0\) due to strict convexity of the objective function and linearity of the constraints.
It is however shown in \cite[section 3.2, p. 22]{Gunn1998} that the solutions that are found with explicit and implicit bias are different.
This results from the fact that in case of implicit bias the variable \(b\) also enters the regularization term.

From now on we work with the implicit bias. To see the derivation of the bilevel problem with the explicit bias compare for \cite[section 2.2]{Kunapuli2008}.

\subsubsection{Multiple Hyper-parameters}

To examine the performance of the bilevel approach in the more dimensional case a model suggested by Moore et al. in \cite{Moore2011} called \emph{multi-group} support vector classification (multiSVC) is used. This model allows different hyper-parameters for different subgroups of the trainings data.
In section 4.3 of \cite{Moore2011} the model is described for a regression function. In this thesis the same technique is used for classification.

The motivation behind the approach is that different groups of samples from the training set can have slightly different properties and should therefore have their own weighting parameters \(C_g\).
On the one hand this can improve the generalization results. On the other hand properties of the different data groups can be identified by their respective hyper-parameters. Moore et al. explain in \cite[section 4.3, p. 9]{Moore2011} that for example a large value of \(C_g\) signifies reliable data in the respective group whereas a smaller \(C_g\) suggests a poorer quality.

To perform multiSVC, divide the trainings data into \(G\) (pairwise disjoint) groups.
Define the vector of hyper-parameters \(C := (C_1,...,C_G)^{\top}\). For the sake of simplicity in this thesis all the groups are of equal size but all derivations are also possible for differently sized groups.

%For \(T\)-fold cross validation the \(t\)'th 
The multi-group classification problem in constrained form can be stated as 

\begin{align}
\begin{split}
	\min_{\tilde{w},\xi} \quad & \frac{1}{2} \|\tilde{w}\|^2+\sum_{g = 1}^G\left(\frac{C_g}{2}\sum_{i \in N_g} {\xi_i^2}\right) \vspace{0.5ex}\\
	\text{s.t.} \quad & y_i\Langle \tilde{w},\tilde{x}^i\Rangle \geq 1 - \xi_i \vspace{0.5ex}\\
	& 	\forall i \in \bigcup_{g =1}^G N_g =\{1,...,n_d\}.
\end{split}
\label{MultiSVC_QP}
\end{align}

Here \(N_g\) is the index set that contains the indices of the data of the \(g\)'th group.


\subsection{Formulation of the Bilevel Problem}
%Check if regression case also included?????

%\textcolor{red}{adapt all section titles -> introduction of MultiGroup}

The hyper-parameters \(C_g\) in the objective function of the classification problem have to be set beforehand. This step is part of the model selection process.
To set the parameters optimally different methods can be used.
A very intuitive and widely used approach is doing \emph{cross validation} (CV) with a grid search implementation \cite[p. 30]{Kunapuli2008}.
%very costly, discrete parameter choice, not practicable in case of many parameter

To prevent overfitting and get a good parameter selection, especially in case of little data, commonly \(T\)-fold cross validation is used \cite[p. 30]{Kunapuli2008}.
For this technique the training data is randomly partitioned into \(T\) subsets of equal size. One of these subsets is then left out of the training set and instead used afterwards to get an estimate of the generalization error. 
To use CV for model selection it has to be embedded into an optimization algorithm over the hyper-parameter space. 
Commonly this is done by discretizing the parameter space and for \(T\)-fold CV training \(T\) models at each grid point. The resulting models are then compared to find the best parameters in the grid.
Obviously for a growing number of hyper-parameters this is very costly. An additional drawback is that the parameters are only chosen from a finite set \cite[p. 30]{Kunapuli2008}.

%\subsubsection{Reformulation as Bilevel Problem}

A more recent approach is the formulation as a bilevel problem used in \cite{Kunapuli2008} and \cite{Moore2011}.
This makes it possible to optimize the hyper-parameters continuously.

%Formal description of the bilevel problem for t-fold cross validation
%Better model description --> see 2.2 (p.46) in thesis 

Let \(\Omega = \{(x^1,y_1),...,(x^{n_d},y_{n_d})\} \subset \R^{n_f+1}\) be a given data set of size \(n_d = |\Omega|\). The associated index set is denoted by \(\mathcal{N}\). For classification the labels \(y_i\) are \(\pm1\).
For \(T\)-fold cross validation let \(\bar{\Omega}_t\) and \(\Omega_t\) be the training set and the validation set respectively within the \(t\)'th fold and \(\bar{\mathcal{N}}_t\) and \(\mathcal{N}_t\) the respective index sets. For multi-group SVC the index set \(\bar{\mathcal{N}}_t\) is again divided into the \(G\) sets \(\bar{\mathcal{N}}_t^g\) to account for the different groups associated with the different hyper-parameters.
Furthermore let \(f^t:\R^{n_f+1} \to \R\) be the response function trained on the \(t\)'th fold and \(\lambda \in \Lambda\) the hyper-parameter to be optimized.
For a general machine learning problem with upper and lower loss function \(\mathcal{L}_{upp}\) and \(\mathcal{L}_{low}\) respectively the bilevel problem reads
 
%%% introduce \mathcal(F) already before as the function space

\begin{equation*}
	\begin{array}{cll}
	\displaystyle\min_{\lambda, f^t} & \mathcal{L}_{upp}\left(\lambda,f^1|_{\Omega_1},...,f^T|_{\Omega_T}\right) & \text{upper level} \vspace{0.5ex}\\
	\text{s.t.} & \lambda \in \Lambda & \vspace{1em}\\
	& \text{for } t = 1,...,T: & \\
	& f^t \in \begin{Bmatrix} \displaystyle\argmin_{f\in \mathcal{F}} & \mathcal{L}_{low}\left(\lambda,f,(x^i,y_i)_{i = 1}^l\in \bar{\Omega}_t\right) \vspace{0.5ex}\\
	                        \text{s.t.} & \mathcal{G}_{low}(\lambda,f) \leq 0 
													\end{Bmatrix}. & \text{lower level}
	\end{array}
\end{equation*}

In the case of multigroup support vector classification the \(T\) inner problems have the SVM formulation %(\ref{SVM_1}) or 
(\ref{MultiSVC_QP}). % (but all \(T\) problems have the same formulation).
This problem can also be rewritten into an unconstrained form. It is helpful when using the inexact bundle algorithm for solving the bilevel problem.
For the \(t\)'th fold the resulting hyperplane is identified with the variable \(\tilde{w}^t \in \R^{n_f+1}\).
The inner level problem for the \(t\)'th fold can therefore be stated as

%\begin{equation}
	%(w^t,b_t) \in \argmin_{w,b}\left\{ \frac{\lambda}{2} \|w\|^2_2+\sum_{i\in \bar{\mathcal{N}}_t}{\max\left(1-y_i(w^{\top}x^i-b),0\right)}\right\}
%\label{lower_t_1}
%\end{equation}

%or

\begin{equation}
	\tilde{w}^t \in \argmin_{\tilde{w}} \left\{\frac{1}{2} \|\tilde{w}\|^2+\sum_{g=1}^G\left(\frac{C_g}{2}\sum_{i\in \bar{\mathcal{N}}_t^g}{\max\left\{1-y_i\Langle \tilde{w},\tilde{x}^i\Rangle,0\right\}^2}\right)\right\}.
\label{lower_unconstr}
\end{equation}

%Where the hyper-parameter \(\lambda = \frac{1}{C}\) is used  due to numerical stability \cite[p. 38]{Kunapuli2008}.

For the upper level objective function different choices are possible. All that are presented here use the implicit bias. They all can also be used with the explicit bias term.

Simply put, the outer level objective should compare the different inner level solutions and pick the best one. An intuitive choice is therefore to pick the misclassification loss, that counts how many data points of the respective validation set \(\Omega_t\) are misclassified when taking function \(f^t\).

The misclassification loss can be written as

\begin{equation}
	\mathcal{L}_{mis}(\tilde{w}) = \frac{1}{T}\sum_{t=1}^T\frac{1}{|\mathcal{N}_t|}\sum_{i \in \mathcal{N}_t}{\left(-y_i\Langle \tilde{w}^t,\tilde{x}^i\Rangle\right)_{\star}},
\label{misclass_loss}
\end{equation}

where the step function \((\cdot)_{\star}\) is defined component wise for a vector as
\begin{equation}
	(r_{\star})_i = \left\{\begin{array}{c} 1, \quad \text{if } r_i > 0, \\ 0, \quad \text{if } r_i \leq 0 \end{array} \right. .
\label{step_fun}
\end{equation}

The drawback of this simple loss function is that it is not continuous and thus not suitable for subgradient based optimization. Therefore another loss function is used for the upper level problem, the \emph{hinge loss} or \emph{L1-loss}. It is an upper bound on the misclassification loss and reads

\begin{equation}
		\mathcal{L}_{hinge}(\tilde{w}) = \frac{1}{T}\sum_{t=1}^T\frac{1}{|\mathcal{N}_t|}\sum_{i \in \mathcal{N}_t}{\max\left\{1-y_i\Langle \tilde{w}^t,\tilde{x}^i\Rangle,0\right\}}.
\label{hinge_loss}
\end{equation}

It is also possible to square the max term. This results in the \emph{L2-loss} function

\begin{equation}
		\mathcal{L}_{hingequad}(\tilde{w}) = \frac{1}{T}\sum_{t=1}^T\frac{1}{|\mathcal{N}_t|}\sum_{i \in \mathcal{N}_t}{\max\left\{1-y_i\Langle \tilde{w}^t,\tilde{x}^i\Rangle,0\right\}^2}.
\label{hingequad_loss}
\end{equation}

We refer to this second loss function also as \emph{hingequad loss}.

%In figure (\ref{??}) it can be seen that its minimum and overall progress is more similar to the misclassification loss than the one of the hinge loss. 
%\textcolor{red}{For this reason we progress taking the squared form of the hinge loss, abbreviating with \emph{hingequad loss} for convenience.\\
%No, take hingeloss because of nonsmoothness}

%\textcolor{red}{also possible to square the max term\\
%formula \\
%from plots: seems to match the misclassification loss a bit better -> used it instead/also}

For the bilevel problem discussed in this thesis the hingequad function is chosen as objective of the upper level problem.
Hence the final resulting bilevel formulation for model selection in multigroup support vector classification is 

%\begin{align}
%\begin{split}
	%\min_{w,\bm{b}} \quad &  \mathcal{L}_{hinge}(w,\bm{b}) = \frac{1}{T}\sum_{t=1}^T\frac{1}{|\mathcal{N}_t|}\sum_{i \in \mathcal{N}_t}{\max\left(1-y_i((w^t)^{\top}x-b_t),0\right)}\\
	%\text{subject to} \quad &  \lambda > 0 \\
	%& \text{for } t = 1,...,T \\
	%& (w^t,b_t) \in \argmin_{w,b}\left\{ \frac{\lambda}{2} \|w\|^2_2+\sum_{i\in \bar{\mathcal{N}}_t}{\max\left(1-y_i(w^{\top}x^i-b),0\right)}\right\} \\
%\end{split}
%\label{model_1}
%\end{align}
%
%and 

\begin{align}
\begin{split}
	\min_{C} \quad &  \mathcal{L}_{hingequad}(\tilde{w}) = \frac{1}{T}\sum_{t=1}^T\frac{1}{|\mathcal{N}_t|}\sum_{i \in \mathcal{N}_t}{\max\left\{1-y_i\Langle \tilde{w}^t,\tilde{x}^i\Rangle,0\right\}^2}\\
	\text{s.t.} \quad & C := (C_1,...,C_G) > 0 \\
	& \text{for } t = 1,...,T \\
	& \tilde{w}^t \in \argmin_{\tilde{w}}\left\{ \frac{1}{2} \|\tilde{w}\|^2+\sum_{g=1}^G\left(\frac{C_g}{2}\sum_{i\in \bar{\mathcal{N}}_t^g}\max\left\{1-y_i\Langle \tilde{w},\tilde{x}^i\Rangle,0\right\}^2\right)\right\}. \\
\end{split}
\label{bilevel_fin}
\end{align}

Obviously this bilevel problem contains the usual support vector classification with only one data group as a special case.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Here \(\bar{\mathcal{N}}_t^g\) the index set that contains the indices of the data in the \(g\)'th group of the \(t\)'th fold.
%
%Reformulation of the lower level objective:
%
%\begin{equation*}
	%\mathcal{L}_{low}(w,b) =  \frac{1}{2} \|w\|^2+\sum_{g = 1}^GC_g\left(\sum_{i\in \bar{\mathcal{N}}_t^g}\max\left\{1-y_i\left(\Langle w,x^i\Rangle-b\right),0\right\}^2\right)
%\label{ll_mult_group}
%\end{equation*}

%\begin{align*}
	%\min_{w,b,\xi} \quad & \frac{1}{2} \|w\|^2_2+\sum_{g = 1}^G\left(C_g\sum_{i \in \bar{\mathcal{N}}_t^g}{\xi_i^2}\right) \vspace{0.5ex}\\
	%\text{s.t.} \quad & y_i\left(\Langle w,x^i\Rangle-b\right) \geq 1 - \xi_i \vspace{0.5ex}\\
	%& 	\forall i \in \bigcup_{g =1}^G \bar{\mathcal{N}}_t^g = \bar{\mathcal{N}}_t
%\label{MultiSVM_QP}
%\end{align*}
%
%the \(\mathcal{N}_t^g\) are pairwise disjoint

%\(w \in \R^n, b\in \R, \xi \in \R^{\vert\bar{\mathcal{N}}_t \vert}\)




\subsection{Solution with the Inexact Bundle Algorithm}

The bilevel problem (\ref{bilevel_fin}) derived above is to be solved with the two bundle algorithms \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1.
This requires having in every iteration an approximate value of the upper level objective function and an approximate subgradient of the upper level objective.

To understand the issues arising when computing especially the subgradient of a bilevel objective consider again the general bilevel problem (\ref{bilevel}).

At the current iterate \(C^k\) the function value of the upper level objective function can be computed by solving the lower level problem given \(C^k\).
The resulting solution \(\tilde{w}^k = (\tilde{w}^{1,k},...,\tilde{w}^{T,k})\) is then inserted into the upper level objective and its value can be calculated.

For computing a subgradient, it is not that simple. Additionally to the variation of the upper level function \(\mathcal{L}_{upp}\) with respect to the variable \(\tilde{w}\) also the variation of the solution \(\tilde{w}^k\) with respect to \(C\) has to be considered.
To do this we follow the strategy described in \cite{Outrata1998}. Refer there also for a more thorough analysis on this subject.

\subsubsection{Assumptions}
\label{sec_str_reg}

Consider the general bilevel problem formulation (\ref{bilevel}) without the explicit constraint \(\mathcal{G}_{upp}(C,\tilde{w}) \leq 0\).
Let the feasible set \(U_{ad}\) be a nonempty compact set and \(\tilde{A}\) an open set containing \(U_{ad}\).
To use the implicit programming approach suggested in \cite{Outrata1998},  the following assumptions have to hold true:

\begin{itemize}
\item[(A1)] The upper level objective \(\mathcal{L}_{upp}\) is continuously differentiable on \(\tilde{A}\times \R^k\).
\item[(A2)] The lower level program possesses a unique solution \(\tilde{w}_C\) for every \(C\in \tilde{A}\).
\item[(A3)] The generalized equation coming from the lower level program is strongly regular at all points \((C,\tilde{w}_C)\), where \(C \in \tilde{A}\) and \(\tilde{w}_C\) is the corresponding solution of the lower level problem.
\end{itemize}

A \emph{(perturbed) generalized equation} (GE) is a relation of the form

\begin{equation}
	0 \in H(C,\tilde{w})+N_{U}(\tilde{w}), 
	\label{GE_gen}
\end{equation}

where \(H:\R^n\times \R^k \to \R^k\) and \(N_{U}(\tilde{w})\) denotes the \emph{normal cone} to the convex set \(U \subset \R^k\) at the point \(\tilde{w}\in \R^k\).

\begin{definition}[{\cite[Definition 2.6, p. 18]{Outrata1998}}]
	Let \(U\) be a convex subset of \(\R^k\) and \(\tilde{w}\) in the closure of \(U\). Then
	
	\begin{equation*}
		N_U(\tilde{w}) := \{\zeta\in \R^k \mid \Langle \zeta,v-\tilde{w}\Rangle \leq 0 \quad \forall v \in U \}
	\label{norm_cone}
	\end{equation*}
	
	is called normal cone to \(U\) at \(\tilde{w}\).
\end{definition}
 
The constraint induced by the inner level problem can be rewritten as a generalized equation via its optimality condition.
Let \(U\) correspond to the feasible set of the inner level problem defined by the intersection of the set \(W\) with the set defined by \(\mathcal{G}_{low}(\bar{C},\tilde{w})\leq 0\) for a fixed variable \(\bar{C} \in U_{ad} \).
Then the lower level problem can be expressed in an unconstrained way by using the indicator function defined in (\ref{indicator_fun}). If the constraint set is convex, the indicator function is a convex function and for every element of its subdifferential the subgradient inequality (\ref{subgr_ineq}) holds.

This yields that for all elements \(\zeta\) of the subdifferential \(\partial \mathtt{i}_U(\tilde{w})\) it holds

\begin{equation*}
\begin{split}
	&\mathtt{i}_U(v)-\mathtt{i}_U(\tilde{w}) \geq \Langle \zeta, v-\tilde{w}\Rangle \quad \forall v \in U \\
	\Leftrightarrow & \Langle \zeta, v-\tilde{w}\Rangle \leq 0 \quad \forall v \in U,
\end{split}
\end{equation*}

because for \(\tilde{w},v \in U\) the indicator function is zero. This means that the subdifferential of the indicator function of the set \(U\) at the point \(\tilde{w}\) coincides with the normal cone to the set \(U\) at the point \(\tilde{w}\) and so for a constrained minimizer of the function \(\mathcal{L}_{low}(C,\cdot)\) on the set \(U\) the following optimality condition holds:

\[ 0 \in \partial \mathcal{L}_{low}(C,\tilde{w}) + N_U(\tilde{w}). \]

If \(\mathcal{L}_{low}\) is continuously differentiable, the function \(\partial \mathcal{L}_{low} = \{\nabla \mathcal{L}_{low}\} : \R^n\times\R^k \to \R^k\) is single valued and continuous and the relation above is a generalized equation.

The strong regularity condition basicly assures, that the GE coming from the lower level problem can provide the needed implicit function.

The following equivalence to this condition is shown in \cite{Outrata1998}:

\begin{proposition}[{\cite[Theorem 5.3, p. 90]{Outrata1998}}]
\label{strong_reg}
	Let the set \(U\) be polyhedral. Then the following statements are equivalent:\\
	(i) The GE (\ref{GE_gen}) is strongly regular at \((C,\tilde{w})\).\\
	(ii) The map
	
		\[ \Lambda : \lambda \mapsto \{\eta \in \R^k \mid \lambda \in \mathcal{J}_{\tilde{w}}H(C,\tilde{w}) \eta + N_K(\eta)\} \]
	
		is single valued on \(\R^{k}\).
		Here \(K\) is the critical cone of \(U\), defined in \cite[equation (2.50), p. 37]{Outrata1998}.
\end{proposition}


%\subsubsection{Conditions on the Lower Level Problem}

Let us now verify the above assumptions (A1) -- (A3) for the hyper-parameter finding bilevel problem (\ref{bilevel_fin}).
First of all, the feasible set \(U_{ad}\), where the hyper-parameter \(C\) is chosen from, has to be a convex compact set. In order to assure that, the constraint on the hyper-parameter \(C\) has to be adapted.
Therefore choose two constants \(l_C, u_C > 0\) with \(l_C < u_C\) constrain the vector \(C\) by the component wise meant inequalities

\[ l_C \leq C \leq u_C. \]

Assumption (A1) is fulfilled as \(\mathcal{L}_{hingequad}\) is a continuously differentiable function because of the squared max-term.

Next assumptions (A2) and (A3) are verified. In order to do this consider the lower level problem in its constrained formulation (\ref{MultiSVC_QP}).
It can be rewritten in matrix form using the following definitions:

\begin{equation*}
\begin{split}
	&H(C):= \begin{pmatrix} \mathbb{I} \\ & \tilde{C}\end{pmatrix}\in \R^{n_1\times n_1} \\
	&A := \begin{pmatrix}	-y_1(\tilde{x}^1)^{\top} & -1 \\
		\vdots & & \ddots \\ -y_N(\tilde{x}^N)^{\top} & & & -1\end{pmatrix} \in \R^{nd \times n_1}, \quad  a:= \begin{pmatrix}-1\\\vdots\\-1\end{pmatrix} \in \R^{nd}.
		\label{matrices}
\end{split}
\end{equation*}

Here \(\tilde{C}\) is a diagonal matrix with the vector \((C_1,...,C_1,...,C_G,...,C_G)^{\top}\) on the diagonal such that the hyper-parameters correspond to the \(\xi_i\) of the different groups. The number \(n_1 = n_f+1+n_d\) where \(n_f\) is the dimension of the feature space and \(n_d\) the number of data points in the sample.

Then the lower level problem can be written as

\begin{align}
\begin{split}
	\min_{\tilde{w},\xi} & \quad \frac{1}{2} (\tilde{w}^{\top},\xi^{\top}) H(C) \begin{pmatrix}\tilde{w}\\\xi\end{pmatrix} \\
	\text{s.t.} & \quad A \begin{pmatrix}\tilde{w}\\\xi\end{pmatrix} \leq a.
\end{split}
\label{low_QP}
\end{align}

This formulation of the lower level problem corresponds to the one in Appendix A.1.3 in \cite{Outrata1998}. Only the objective function depends on the hyper-parameter \(C\), not the constraints.

Problem (\ref{low_QP}) has a strictly convex objective function and linear constraints. Therefore it possesses a unique global minimizer. Denoting the vector of all slack variables \(\xi_i\) with \(\xi\) this minimizer is given by \(((\tilde{w}^*)^{\top},(\xi^*)^{\top})^{\top}\). It depends on the vector of hyper-parameters \(C\).

Due to convexity, for this problem the KKT conditions are necessary and sufficient. This means that at the minimum \(((\tilde{w}^*)^{\top},(\xi^*)^{\top})^{\top}\) holds

\begin{align*}
	& \text{there is } \mu^* \in \R^{nd} \text{ such that} \\
	&\nabla_{(\tilde{w},\xi)} L(C,\tilde{w}^*,\xi^*,\mu^*) = 0 \\
	& \mu^* \geq 0, \quad A \begin{pmatrix}\tilde{w}^*\\\xi^*\end{pmatrix} \leq a, \quad \Langle\mu^*,\left(A \begin{pmatrix}\tilde{w}^*\\\xi^*\end{pmatrix} - a\right)\Rangle = 0,
\end{align*}

for a given \(C\), where \(L(C,\tilde{w},\xi,\mu) = \frac{1}{2}(\tilde{w}^{\top},\xi^{\top})H(C)(\tilde{w}^{\top},\xi^{\top})^{\top}+\Langle\mu,\left(A (\tilde{w}^{\top},\xi^{\top})^{\top} - a\right)\Rangle\) is the Lagrangian of the problem and \(\mu^*\) the multiplier corresponding to the inequality constraints.

Using the KKT conditions a special GE can be derived for problem (\ref{low_QP}):

\begin{equation}
	0 \in \begin{bmatrix} \nabla_{(\tilde{w},\xi)}L(C,\tilde{w},\xi,\mu)\\ - A \left(\tilde{w}^{\top},\xi^{\top}\right)^{\top} + a\end{bmatrix} + N_{\R^{n_f+1}\times\R^{n_d}_+}.
\label{GE}
\end{equation}

The derivation of this particular form of a GE is given in \cite[chapter 4, p. 71--72 and chapter 5, p. 92]{Outrata1998}.

This new GE is very convenient due to the simple structure of the cone but it depends now also on the Lagrange multiplier \(\mu\). Therefore this multiplier also has to be unique at the solution \(((\tilde{w}^*)^{\top},(\xi^*)^{\top})^{\top}\).
To check this introduce the following index sets:

\begin{align*}
	& I(\tilde{w},\xi) = \{i \in \{1,...,n_d\} \mid A (\tilde{w}^{\top},\xi^{\top})^{\top} - a = 0\} \\
	& I_+(\tilde{w},\xi) = \{i\in I(\tilde{w},\xi) \mid \mu_i > 0\},
\end{align*}

which denote the set of \emph{active} and \emph{stronly acitve} inequality constraints respectively.
The set \(I_+\) also depends on the multiplier \(\mu\). In cases where \(\mu\) is not unique, this has to be indicated by writing \(I_+(\tilde{w},\xi,\mu)\).  As it is shown in the following that for the presented problem the multiplier \(\mu\) is always unique, it is however omitted in the specification of \(I_+\). 

To assure that the optimal Lagrange multiplier \(\mu^*\) is unique, we show that the \emph{linear independence constraint qualification} (LICQ) holds in every minimum  \(((\tilde{w}^*)^{\top},(\xi^*)^{\top})^{\top}\) \cite[Theorem 4.8, p. 82]{Outrata1998}, \cite[Theorem 1, p. 3]{Wachsmuth2013}.

In the present case, where there are only inequality constraints, the LICQ holds at a point \((\tilde{w},\xi)\) if the rows of the matrix \(\mathcal{J}_{(\tilde{w},\xi)}\left(A(\tilde{w}^{\top},\xi^{\top})^{\top} - a\right) = A\) that correspond to the indices in \(I(\tilde{w},\xi)\) are linearly independent \cite[p. 82, 96]{Outrata1998}.

For problem (\ref{low_QP}) the LICQ holds at every feasible point \((\tilde{w},\xi)\) because all rows of the matrix \(A\) are linearly independent. This means that linear independence particularly holds for all rows corresponding to the active constraints at any minimum \((\tilde{w}^*,\xi^*)\).
Hence the lower level problem possesses a unique solution vector \((\tilde{w}^*,\xi^*)\) and a unique corresponding Lagrange multiplier \(\mu^*\) for every hyper-parameter (vector) \(C\). Thus assumption (A2) is fulfilled.


Finally to show that assumption (A3) holds, strong regularity has to be shown for the generalized equation (\ref{GE}).
This is done by using Theorem 5.8 in \cite[p. 96]{Outrata1998}.

For stating the theorem the following definition is needed:
\begin{definition}[{\cite[Definition 4.4, p. 81]{Outrata1998}}]
	Let \(M \in \R^{n\times n}\) be a matrix and \(K \subset \R^n\) a cone. The matrix \(M\) is strictly copositive with respect to \(K\) if 
	\[ \langle d,Md \rangle > 0 \quad \text{for all} \quad d \in K, d\neq 0. \]
\end{definition}

\begin{theorem}[c.f. {\cite[Theorem 5.8, p. 96]{Outrata1998}}]
	Suppose that LICQ holds at \((\tilde{w},\xi)\) and that the matrix \(\mathcal{J}_{(\tilde{w},\xi)}\left(\nabla_{(\tilde{w},\xi)}L(C,\tilde{w},\xi,\mu)\right)\) is strictly copositive with respect to the kernel of the matrix \(A_{I_+}\). \\
	Then the GE (\ref{GE}) is strongly regular at \((C,\tilde{w},\xi,\mu)\).
\end{theorem}

To assure that the Hessian of the Lagrangian is well defined, the lower level objective function has to be two times continuously differentiable. This is given for the quadratic objective function of (\ref{low_QP}) and it holds that 

\[\mathcal{J}_{(\tilde{w},\xi)}\left(\nabla_{(\tilde{w},\xi)}L(C,\tilde{w},\xi,\mu)\right) = \begin{pmatrix} \mathbb{I} \\ & \tilde{C}\end{pmatrix}. \] 
%From the LICQ follows that the KKT multiplier \(\mu^*\) at a minimum \((\tilde{w}^*,\xi^*)\) is unique.
%The matrix \(A_{I_+(\tilde{w}^*,\xi^*,\mu^*)}\) contains only the rows of the matrix \(A\) corresponding to strongly active constraints. 

Because all components of the vector \((C_1,...,C_1,...,C_G,...,C_G)^{\top}\) are greater than zero, this matrix is positive definite and as such strictly copositive on the whole \(\R^{n_f+1+n_d}\).
This means that all necessary conditions are fulfilled in order to compute a subgradient with respect to \(C\) of the upper level objective function \(\mathcal{L}_{upp}(C,\tilde{w}(C))\) in the way presented in \cite{Outrata1998}.

\subsubsection{The Adjoint Problem}

In order to calculate the needed subgradient of bilevel problem the technique of \emph{adjoint equations} is used. This technique is well known from optimal control (c.f. \cite[p. 126]{Outrata1998} and references therein). For the derivation of the adjoint problem and the results used below, refer to chapters 6 and 7 of \cite{Outrata1998}. 

The adjoint problem to the given bilevel problem (\ref{bilevel_fin}) can be stated as the following constrained quadratic problem using the expressions defined in (\ref{matrices}):

\begin{equation}
\begin{split}
	\min_{p} & \quad\frac{1}{2}\Langle p,H(C)p\Rangle - \Langle \nabla_{(\tilde{w},\xi)} \mathcal{L}_{upp}(\tilde{w},\xi),p\Rangle \\
	\text{s.t.} & \quad A_{I_+M}p = 0.
\end{split}
\label{adj_prob}
\end{equation}

Here the index set \(I_+M = I_+(\tilde{w},\xi) \cup M_i(\tilde{w},\xi)\).
The set \(M_i(\tilde{w},\xi) \subset I(\tilde{w},\xi) \setminus I_+(\tilde{w},\xi)\) is a subset of the inequality constraints, that are active but not strictly active at the point \((\tilde{w},\xi)\) and has to be chosen suitably.
What this means is explained next.

First introduce the notation \(I_0(\tilde{w},\xi) = I(\tilde{w},\xi) \setminus I_+(\tilde{w},\xi)\). Constraints whose indices are in this set are also calles \emph{weakly active}. Let \(\mathcal{P}(I_0(\tilde{w},\xi))\) be the power set of this index set and \(\mathbb{K}(\tilde{w},\xi)\) an index set that contains indices for all elements of the set \(\mathcal{P}(I_0(\tilde{w},\xi))\). The index set \(M_i(\tilde{w},\xi)\) is then the element of \(\mathcal{P}(I_0(\tilde{w},\xi))\) corresponding to the index \(i \in \mathbb{K}(\tilde{w},\xi)\).
To ensure a proper choice of the index set \(M_i(\tilde{w},\xi)\) \cite{Outrata1998} offers a theorem and a corollary that are applicable in the given context.

For better readability the brackets behind the index sets are omitted. All index sets refer to the same point.

\begin{theorem}[c.f. {\cite[Theorem 7.10, p. 137]{Outrata1998}}]
	\label{theo_710}
	Consider the GE (\ref{GE}) at the point \((C,\tilde{w},\xi,\mu)\). Suppose that the assumptions (A2) and (A3) hold and that for a given \(i\in \mathbb{K}(\tilde{w},\xi)\) the following system in \((z_1,z_2,z_3,z_4)\) is inconsistent:
	
	\begin{align*}
		-(A_{I_0 \setminus M_i})^{\top}z_1+(H(C))^{\top}z_3-(A_{I_+\cup M})^{\top}z_4 &= 0 \\
		z_2+A_{M_i}z_3 &= 0\\
		\left(\mathcal{J}_C\left(H(C)(\tilde{w},\xi)^{\top}\right)\right)^{\top}z_3 &= 0 \\	
		(z_1,z_2) \geq 0, \quad (z_1,z_2) &\neq 0 \\
		z_3 \in \ker(A_{I_+}).
	\end{align*}
	
	Then subgradient can be calculated via the method above.
\end{theorem}

\begin{corollary}[c.f. {\cite[Corollary 7.12, p. 139]{Outrata1998}}]
	Let the assumptions of Theorem \ref{theo_710} be fulfilled. Suppose that the constraints do not depend on the variable \(C\) and that 
	
	\[  \ker\left(\mathcal{J}_C\left(H(C)(\tilde{w}^{\top},\xi^{\top})^{\top}\right)^{\top}\right) \cap \ker\left(A_{I_+}\right) = \{0\} .\]
	
	Then the subgradient can be calculated via the method above for each \(i \in \mathbb{K}(\tilde{w},\xi)\).
\end{corollary}

Neither the assumptions of the corollary nor those of the theorem can be assured in general. They have therefore to be checked for the specific situation in every iteration.
For the specific instances used for the numerical experiments in this thesis there never existed any weakly active constraints. So in this thesis the set \(M_i(\tilde{w},\xi)\) was always chosen empty.





%\textcolor{red}{ now adjoint problem\\
%Remark on M\\
%what about \(M_i\) \\}

%In order to do this the lower level problem is considered in its constrained form. 

%Let \(\tilde{w}^*\in \R^{n+1}\) denote the unique solution of the unconstrained problem. 
%
%Due to the equivalence of the two problem formulations the optimal slack variables of the constrained problem are given by \(\xi_i^* = 1-y_i\Langle \tilde{w}^*,\tilde{x}^i\Rangle\).


\subsection{On Error Bounds and Regularity}

In order to use algorithms \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1, some properties are required of the objective function and the nature of the inexactness. In this section we give a short comment on how far theses properties can be met.


\subsubsection{Error Bounds}

It is assumed in (\ref{err_bound}) that the error on the function value and subgradient are bounded. This bound does not have to be known, but it has to exist and allows an estimation of the possible accuracy to which the algorithms can solve the given problem (c.f. Lemma \ref{Lemma5}).

Due to the complicated structure of bilevel problems no tight error bounds can be given for problem (\ref{bilevel_fin}) but the existence of general error bounds can be shown.

%no ``usefull'' error bounds due to complicated structure of bilevel problem \\
%only can show that there exist some bounds \\

The error on the function value in bilevel problems originates from the fact, that in the implicit approach the numerically calculated minimal point of the lower level is inserted into the upper level function.
Of course, this optimal point can only be approximated to a given tolerance.
As the lower level problem of (\ref{bilevel_fin}) is a strictly convex quadratic optimization problem, a very common stopping criterion is to check for approximate first order optimality.

For constrained problems first order optimality means that the KKT conditions (which are necessary and sufficient in the convex case) are fulfilled.
Approximate optimality then means, that the conditions hold true within the bounds of a chosen stopping tolerance \(\mathtt{tol}
 >0\).

The solver that is used for the numerical solution of the problem in this thesis is the \texttt{quadprog} solver from MATLAB. This solver uses the above stopping condition scaled by the input values \cite{2017}.

This  however cannot give an estimate for the minimizing argument of the lower level objective.
This can be seen when taking a strictly convex whose slope is so small, that the stopping condition is fulfilled for every point on a compact subset of the feasible set \(U_C\).
In this case also the approximate minimizing point found by any algorithm can be any point in \(U_C\). 

It still can be assured, that the minimizer \(\tilde{w}\) found by an algorithm is not infinitely far away from the exact minimizer \(\tilde{w}^*\).
This follows immediately if the constraint set is compact. If it is unbounded in any direction this follows from strict convexity.
Without loss of generality instead of the KKT conditions one can consider the first order optimality condition in the unconstrained case, namely that the norm of the gradient at a minimizer is zero. (Due to unboundedness of the constraint set in the examined directions, the problem can be treated as an unconstrained one for them. In the direction where the constraint set is bounded, possible choices for \(\tilde{w}\) are also bounded.)
For strictly convex functions the gradient is strictly monotone, hence the area where its norm is smaller or equal to any chosen tolerance is compact. This means that in this case all possible choices of \(\tilde{w}\) are bounded.

Using local Lipschitz continuity of the upper level objective function on the admissible set we can conclude that

\[ \Vert \mathcal{L}_{upp}(\tilde{w})-\mathcal{L}_{upp}(\tilde{w}^*) \Vert \leq L_{upp}\Vert \tilde{w}-\tilde{w}^* \Vert \leq  L_{upp} D_{\tilde{w}}(\mathtt{tol}), \]

where \(  L_{upp}\) is the Lipschitz constant of the upper level objective on the admissible set. The number \(D_{\tilde{w}}(\mathtt{tol})\) is the maximal distance of points \(\tilde{w}_1\) and \(\tilde{w}_2\) in the compact set originating from the intersection of the constraint set and the set where the lower level objective has a gradient smaller than the chosen tolerance \(\mathtt{tol}\). 
%Observing this, it is known however from \textcolor{red}{\cite[chapter 5]{Outrata1998}} that in case of strong regularity the solution map \textcolor{red}{\(C = S(\tilde{w})\)} is single valued and Lipschitz on the admissible set \textcolor{red}{U_{\textup{ad}}}.
%This means that particularly for the exact minimizing argument \(\tilde{w}^*\) and for all \textcolor{red}{w im Urild der solution map...} the following estimate holds:
%
%\[ L_S\Vert \tilde{w}-\tilde{w}^* \Vert .\]
%

An equally loose bound can be provided for the approximate subgradient via local Lipschitz continuity of the upper level objective and Lipschitz continuity of the solution map \cite[chapter 5]{Outrata1998}.
The inexactness of the subgradient has two reasons. On the one hand the subgradient is not calculated at the exact minimizer \(\tilde{w}^*\) but at an approximated point \(\tilde{w}\).
As the subdifferential is bounded by the Lipschitz constant on \(U_{ad}\) the bound for that part of the subgradient error that originates from taking the subgradient only at an approximate point is given by \(2L_{upp}L_{w}\). Here \(L_{\tilde{w}}\) is the Lipschitz constant of the solution function \(\tilde{w}(C)\).


%Here the theory yields that
%\[ \Vert \mathcal{L}_{upp}(\tilde{w}(C_1))-\mathcal{L}_{upp}(\tilde{w}(C_2)) \Vert \leq L_{upp}\Vert \tilde{w}(C_1)-\tilde{w}(C_2) \Vert \leq  L_{upp} L_{w}\Vert C_1-C_2\Vert, \ \forall C_1, C_2 \in U_{ad}. \]


On the other hand for computation of the subgradient the adjoint problem (\ref{adj_prob}) has to be solved numerically and therefore only gives an approximate solution.
As the adjoint problem is also a strictly convex constrained optimization problem its minimizing argument \(p\) can be estimated the same way as above.

%Hence the following inequality can be stated for the error:
Hence the distance between the exact subgradient and the approximate one in the sense of \(p\) is

\begin{align*}
	\Langle \mathcal{J}_CH(C)\tilde{w}^*, (p^*-p) \Rangle &\leq \Vert \mathcal{J}_CH(C) \Vert_2 \Vert\tilde{w}^* \Vert \Vert p^*-p \Vert \\
	& \leq \Vert \max\{1,C_{max}\} \Vert \tilde{w}_{max}  D_{p}(\mathtt{tol}).
\end{align*}

Here \(C_{max}\) denotes the maximum component of the vector of hyper-parameters and \(\tilde{w}_{max}\) is the maximum of the function \(\tilde{w}(C)\) on \(U_{ad}\).
The sum of those bounds is the overall bound of the approximate subgradient error.
%\textcolor{red}{check this inequality once again}
%\(D_{p}\) 'diameter' for \(p\).


%\( f^j = \mathcal{L}_{upp}(C^j) = \mathcal{L}_{upp}(w(C^j))\) \\
%\(w(C^j) \neq w^*(C^j)\)\\
%Due to the compactness of the feasible set of the lower level problem there is a bound on how far \(w\) can be away from \(w^*\) (not more then the diameter of the feasible set) \\
%Due to Lipschitz continuity of the upper level objective and the implicit function \(w(C)\) there is also a general bound on the subgradients of the upper level problem (the combines Lipschitz constant)

\subsubsection{Regularity}

For the proof of Lemma \ref{Lemma5} subdifferential regularity of the upper level objective function with the solution map inserted is required.

We have however to remark here, that from Proposition 7.4 in \cite{Outrata1998} only follows weak semismoothness of this function.
In \cite[p. 82]{Spingarn1981} an example is given that semismooth, quasidifferentiable function does not have to be subdifferentially regular. As semismooth functions are a subset of weakly semismooth functions, we cannot conclude that the objective function of (\ref{bilevel_fin}) with the solution of the lower level plugged in is regular.

Proving regularity for the particular instance (\ref{bilevel_fin}) of a bilevel problem may be possible, taking into account the structure provided by the strictly convex objective functions of both levels and the fact that the class of semismooth and regular functions is identical to the class of lower-\(\mathcal{C}^1\) functions \cite[equation (3), p. 5]{Hare2016}. It lies however beyond the scope of this thesis.

%\textcolor{red}{equivalent to lower-1}

%actually in Lemma 5 of \cite{Hare2016} the regularity of the objective function is needed because it entails outer semicontinuity of the subdifferential. If this is not the case, then only upper semicontinuity of the subdifferential is given.
%Therefore I don't know if Lemma 5 still holds.

%known to show regularity: local Lipschitz property of solution map\\
%weak semismoothness of upper level objective with solution map inserted (p.134)\\
%Solution map also semismooth? (p. 9)\\
%def (weak) semismoothness p. 32

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Numerical Experiments}

In this section the two bundle algorithms \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1 are applied to solve the classification tasks described above.
The algorithms are compared to the MATLAB routines \texttt{fminsearch} and \texttt{fminbnd} in the one dimensional case and to \texttt{fmincon} for the multiGroup application.

%\textcolor{red}{more}

\subsubsection{The Data}
There are five data sets used. Two of them are real world data sets available on the UCI Machine Learning repository \cite{Lichman2013} and three synthetic data sets.
The synthetic data sets were particularly designed for the optimization of the hyper-parameter \(C\).

A correct choice of the hyper-parameter is particularly important in the case were the data of the different folds is especially sensitive to overfitting.
This is the case in the following situation: The data of each of the different folds is nearly separable, but only with a rather small margin. Additionally, the optimal hyperplanes for the different folds have different directions from the optimal hyperplane, because they are only fitted to minimize the error on the training set.

This situation is shown in the figures below for the synthetic data set \texttt{synsmall}.


\begin{figure}[ht]
	\begin{subfigure}[t]{0.49\textwidth}
		\includegraphics[width=\textwidth]{Pictures/Plots/plot_all_data_all_w.eps}
	\end{subfigure}
	\begin{subfigure}[t]{0.49\textwidth}
			\includegraphics[width=\textwidth]{Pictures/Plots/Fold_1.eps}
	\end{subfigure}
	\begin{subfigure}[t]{0.49\textwidth}
		\includegraphics[width=\textwidth]{Pictures/Plots/Fold_2.eps}
	\end{subfigure}
	\begin{subfigure}[t]{0.49\textwidth}
			\includegraphics[width=\textwidth]{Pictures/Plots/Fold_3.eps}
	\end{subfigure}

	\caption[Overfitting]{The figure on the top left shows the \textup{\texttt{synsmall}} data set. The solid line is the optimal decision line, with the margin indicated as dotted lines on either side of it. The unregularized decision boundaries for the single folds are drawn with dashed lines. \\
	The other three plots show the training data corresponding to the first to third fold of the \textup{\texttt{synsmall}} set and the corresponding unregularized decision lines.}
	\label{fig_synsmall}
\end{figure}

It can be seen, that the data sets of the different folds are all linearly separable, but only for very specific hyperplanes with a small margin.
These hyperplanes can be found by leaving the regularization term \(\frac{1}{2}\Vert \tilde{w}\Vert\) out of the objective function.
It can also be seen, that the optimal hyperplane found if \(C\) is chosen optimally, is similar to only two of the dashed lines. The line found for the second fold is very different to those.

The situation shown in the plots can also be expressed in numbers. Remember that the margin is proportional to the inverse of the norm of the vector \(w\). The matrix containing the vectors for the different folds is given as

\[ W = \begin{pmatrix} 116.7223 & 10.2238 & 26.9331 \\
                      -103.4875 & -19.8813& -26.6014\end{pmatrix}\]

and the bias as \(b = ( 20.2872, 0.7818, 0.679)\).
											
One can already see that the norms of the vectors are rather large: The norms are \(\textup{norm}(w^1)= 155.9928\), \(\textup{norm}(w^2)= 22.3560\) and \(\textup{norm}(w^1)= 37.8554\) for \(W = (w^{1},w^2,w^3)\).
Compare this to the optimal plane \((w,b)\): Here \(w = (2.7842, -2.9033)\), \(b =0.2239\) and \(\textup{norm}(w)=4.0226\).

For linear classification, the danger of overfitting is rather small. This is also indicated by the fact that from a group of different real world data sets, only the two used here provide better results with the regularization term than without it.
However, the chance of overfitting is higher the richer the class of functions is, that is used to separate the two classes \cite[p. 2-4]{Kunapuli2008}. This means, that in case of nonlinear classification overfitting can become a problem. 
There is also a third situation where overfitting can occur more often. This is when the data set consists of relatively little data compared to the number of features. In this case overfitting can happen more often already for linear classification, because the high dimensional space in which the hyperplane lies offers more degrees of freedom to fit the plane to the data.

The two real world data sets used in this thesis are the Breast Cancer Wisconsin data set and Johns Hopkins University Ionosphere database. We refer to them as \texttt{cancer} and \texttt{ionosphere}, respectively.
The three two dimensional synthetic data sets are called \texttt{synbox}, \texttt{synsmall} and \texttt{synbig}.

For the \texttt{synbox} data set, two groups of data were uniformly distributed over two boxes of size \(4\times2\). For the four different folds the boxes are located differently: In the first fold, the boxes are positioned directly above each other, without any overlapping. This means that the data in this fold is linearly separable.
For the second to fourth fold, the upper box  is gradually pushed down 'into' the lower box, such that the data is not linearly separable any more.

For the \texttt{synsmall} and the \texttt{synbig} data sets,  the two groups are normally distributed in two dimensions with mean being \(\mu^1 = (2,3)^{\top}\)for the first group and \(\mu^2 = (-1,9)^{\top}\) for the second group. The covariance is given by
 \[\Sigma = \begin{pmatrix}1.5 & 1.5\\1.5 & 3\end{pmatrix}\] for both groups. 
The data set \texttt{synbig} is a very large data set to test the performance of the different algorithm when handling such data sets.
For both sets the different folds are chosen in a way that they are separable but the separating hyperplane does not give a good generalization.

All data sets were standardized to have a zero mean and unit standard deviation. Then the data sets were split up into three (four) folds of equal size. It is shown in \cite[p. 47]{Kunapuli2008} that this is a reasonable number of folds.
From the two real world data sets, a part of the data is hold back for validation purposes (in table \ref{tab_set_props} marked with \(n_v\)).
The real world data sets were randomly put into the folds. For the synthetic data sets the folds were selected as described above. The number of instances and number of features of every data set is given in Table \ref{tab_set_props}. 

\begin{center}
\begin{table}[H]%
	\begin{tabular}{|lcccc|}
		\hline
    Data set & \(n_d\) & \(n_v\) &  \(n_f\) & \(T\) \\
		\hline
		\texttt{cancer} & 240 & 443 & 9 & 3 \\
		\texttt{ionosphere} & 240 & 111 & 33 & 3 \\
		\texttt{synbox} & 600 && 2 & 4 \\
		\texttt{synsmall} & 600 && 2 & 3 \\
		\texttt{synbig} & 30000 && 2 & 3 \\
		\hline
	\end{tabular}
	\caption[Properties of data sets, 1D]{Properties of the used data sets for one-dimensional optimization.}
	\label{tab_set_props}
\end{table}
\end{center}

\subsubsection{Choice of Parameters}

The bilevel problem (\ref{bilevel_fin}) is solved with the two presented bundle algorithms \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1.
For bilevel problems it is not possible to evaluate the upper level objective without solving the lower level problem first. Also additional steps are necessary to calculate a subgradient.

For the numerical calculations done in this sections, the bundle algorithms therefore work after the following algorithmic pattern, which is inserted into the respective routines described in chapters \ref{sec_nonconv_inex} and \ref{sec_variable_metric}.

\begin{minipage}\linewidth
\vspace{1em}
\hrule  \vspace{0.4ex} \hrule
\vspace{1ex}
\textbf{Algorithmic Pattern \ref{sec_bilevel}.1}
\vspace{1ex}
\hrule
\vspace{1ex}
Initialize the algorithm.
\end{minipage}

For \(k = 1,2,3,  \dotsc \)   

\begin{enumerate}
	\item Calculate the step \(d^k\) by solving bundle subproblem (\ref{bundle_subprob_noncnov_inex}) or (\ref{Q_subprob}) and the new iterate \(C^{k+1} = C^k+d^k\).
		\item Solve the lower level of bilevel problem (\ref{bilevel_fin}) with a QP solver for \(C^{k+1}\). 
	\item Calculate a subgradient of the upper level function by solving the adjoint problem (\ref{adj_prob}).
	\item Calculate the aggregate objects, update all necessary variables and test for a serious step as given in the respective bundle algorithm.
	\item STOP if a stopping condition is matched.
\end{enumerate}
\vspace{1ex}
\hrule

\vspace{1.5em}

The bundle algorithms are set up with the following parameter values: The descent parameter \(m\) is set to 0.05, \(\gamma = 2\), the initial step size is \(t_0 = 0.1\) and the step size updating parameters are \(\kappa_{-} = 0.8\) and \(\kappa_{+}=1.2\).
Elements are added to the bundle if the corresponding Lagrange multiplier \(\alpha^k_j > 10^{-15}\).
%The constraint set that assures that all iterates of the bundle algorithms are bounded is the set \(\{\tilde{w} \in \R^{n_f} \mid \tilde{w}  \}\).
For method \ref{sec_variable_metric}.1 the scaled BFGS update is used with the threshold being \(q=10^8\).
Both algorithms stop if either the decrease measure \(\delta_k\) is smaller than a certain tolerance or if a maximum number of steps of 1000 is reached. The bundle subproblems are solved to a tolerance of \(10^{-15}\) or stop after 5000 iterations. They are solved with MATLAB's \texttt{quadprog}.
Finally the overall optimization variable \(C\) is constrained component wise to \(10^{-5} < C < 10^4\).


The bundle methods \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1 are compared to different MATLAB routines.
These only work with the function values and do not need to have a derivative or subgradient provided by the user.
For every evaluation of the upper level objective function first the \(T\) lower level problems are solved. Then the resulting hyperplanes \(\tilde{w}^t\), \(t=1,...,T\) are plugged into the upper level objective to calculate the loss.

All calculations were done on an Intel i5 2.6~GHz with four kernels.


\subsubsection{One-dimensional Optimization}

First the algorithms are tested for the one-dimensional case.
Here the bundle methods are compared to the \texttt{fminbnd} algorithm \texttt{fminsearch}. Both can solve one-dimensional optimization problems.
It has to be remarked here, that the \texttt{fminsearch} routine does not accept any bounds on the optimization variable. Strictly speaking it could thus give negative values for \(C\), which are infeasible. This did however not happen in any of the experiments.

In the one dimensional case it is possible to plot the objective function values of the bilevel problem. The plots are given in Figure \ref{fig_C_vs_err}.

\begin{figure}[ht]
	\begin{subfigure}{0.46\textwidth}
		\includegraphics[width=\textwidth]{Pictures/Plots/CanIonBox_fin.eps}%
	\end{subfigure}
	\begin{subfigure}{0.52\textwidth}
		\includegraphics[width=\textwidth]{Pictures/Plots/SysSyb_fin.eps}%
	\end{subfigure}
	\caption[Objective function values]{Plots of the hingquad error for different $C$-values values. The figure on the left shows the plot for the \textup{\texttt{cancer}}, \textup{\texttt{ionosphere}} and \textup{\texttt{syn box}} data sets. The plot on the right depicts the situation for the sets \textup{\texttt{synsmall}} (left axis) and \textup{\texttt{synbig}} (right axis).}%
	\label{fig_C_vs_err}%
\end{figure}

Different aspects of the algorithms are compared for various choices  of the starting value, scaling of the objective function, stopping tolerances and exactness of the subroutines.

%One can see that the values of the objective functions are rather small. Therefore also different scaled versions of the upper level objectives are compared to each other in this section.

At first the behavior of the different algorithms regarding differently scaled upper level objective functions and the sensitivity of the different methods towards the starting value are analyzed.

The starting values \(C_0 \) are taken from the set \(\{10^{-5},0.01,1,20,100\}\). The \texttt{fminbnd} algorithm does not need any starting value.
In Figure \ref{fig_C_vs_err} it can be seen, that especially for the sets \texttt{synsmall} and \texttt{synbig} the objective functions are very flat. In order to increase the accuracy, the objective functions are scaled in the following experiment.
We compare the unscaled version of the hingequadloss and a scaled version with scaling factor 100.
The stopping tolerance of all methods is set to \(\texttt{tol} = 10^{-6}\).

For this comparison the lower level problem as well as the adjoint problem of the bundle methods are solved with a tolerance of \(10^{-15}\) for the constraints and optimality condition.
Both problems are solved with the MATLAB QP solver \texttt{quadprog} which stops after meeting the tolerance or after a limit of 1000 iterations is reached.

\begin{figure}[ht]
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{Pictures/Plots/Scal1_ll-15C.eps}%
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{Pictures/Plots/Scal100_ll-15C.eps}%
	\end{subfigure}
	\caption[Minimizer for different starting values and scalings]{The plots show the minimizers found by \textup{\texttt{fminseach}} and the two bundle methods for different starting values on the different data sets. For each data set, the lines next to each other show the result for the starting values \(C_0 = (10^{-5},0.01,1,20,100)\).\\
	The Plot on the left shows the situation for the unscaled objective function. For the plot on the right the objective is scaled by 100.\\
	The first three data sets are measured with the scale on the left, the other two data sets with the scale on the right.}%
	\label{fig_ll15_sc1100_C}%
\end{figure}

\begin{figure}[ht]
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{Pictures/Plots/Scal1_ll-15f.eps}%
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{Pictures/Plots/Scal100_ll-15f.eps}%
	\end{subfigure}
	\caption[Minimium for different starting values and scalings]{The plots show the minimal value found by \textup{\texttt{fminseach}} and the two bundle methods for different starting values on the different data sets. For each data set, the lines next to each other show the result for the starting values \(C_0 = (10^{-5},0.01,1,20,100)\).\\
	The Plot on the left shows the situation for the unscaled objective function. For the plot on the right the objective is scaled by 100.\\
	The first three data sets are measured with the scale on the left, the other two data sets with the scale on the right.}%
	\label{fig_ll15_sc1100_f}%
\end{figure}

In figures \ref{fig_ll15_sc1100_C} and \ref{fig_ll15_sc1100_f} the minimizers and function values found for the different starting values and scaling factors are depicted for the different solution methods.
It can be observed from the plots, that \texttt{fminsearch} finds the same minimizers for all starting values and both scaling functions.
For the two bundle methods, it depends on the starting value, whether a good minimizer is computed. For the unscaled version of the objective function, the bundle methods often stop without any calculations, reporting the starting value as optimal. This happens more often for the larger starting values 20 and 100.
For the \texttt{synsmall} data set it depends on the starting value, weather the local or the global minimum is found.

For the starting value \(C_0 =1\) and the scaling factor 100 decent results are achieved.
Hence for this parameter combination the results of all four methods used, are presented more accurately in table \ref{scal_100_ll15}.

\begin{table}[ht]%
\centering
\begin{tabular}{|l|c|c|c|c|c|}
	\hline
	Data set &  & Bundle \ref{sec_nonconv_inex}.1 & Bundle \ref{sec_variable_metric}.1 & \texttt{fminsearch/bnd} \\
	\hline
	\texttt{cancer} & \(C_{min}\) & 0.0603 & 0.0603 & 0.0604\\
		& \(f\) value & 11.9644 & 11.9644 & 11.9644\\
		& time (s)& 5 & 13 & 4/2\\
		\hline
	\texttt{ionosphere} & \(C_{min}\) & 0.0281 & 0.0238 & 0.0236\\
		& \(f\) value & 43.5899 & 43.5242 & 43.5241\\ 
		& time (s)& 2284 & 1729 & 6/30\\
		\hline
	\texttt{synbox} & \(C_{min}\) & 0.1592 & 0.1535 & 0.0135\\
		& \(f\) value & 60.4899 & 60.2966 & 51.7078 \\
		& time (s)& 255 & 331 & 26/549 \\
		\hline
	\texttt{synsmall} &  \(C_{min}\) & 5.0112 & 5.0228 & 6.6372\\
		& \(f\) value & 1.6520 & 1.6520 & 1.6470 \\
		& time (s)& 4 & 6 & 11/7\\
		\hline
	\texttt{synbig} & \(C_{min}\) & 16.4743 & 16.4965 & 16.4595 \\
		& \(f\) value & 0.0193 & 0.0193 & 0.0193\\
		& time (s)& 593 & 595 & 673/306\\
		\hline
\end{tabular}
\caption[Minimizer, function value and computation time for accurately solved subproblems]{This table shows the minimizer, corresponding minimal function value and the needed computation time of the four tested routines \textup{\texttt{fminsearch}}, \textup{\texttt{fminbnd}}, algorithm \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1.\\
The starting value is \(C_0 = 1\) and the used objective function is scaled with 100.}
\label{scal_100_ll15}
\end{table}


One can see that the MATLAB methods \texttt{fminsearch} and \texttt{fminbnd} solve the problem very accurately.% and reached the same values to the order depicted here, this is why the results are presented in only one row.
The routine \texttt{fminsearch} arrives at the same minimizers as \texttt{fminbnd}. Sometimes it needs however more computation time. This is particularly notable for the data set \texttt{synbig}, where \texttt{fminbnd} needs less than half of the solution time of \texttt{fminsearch}.
Both algorithm reach the minimizers that can be identified from the plots to an accuracy of about \(10^{-6}\). For the \texttt{synsmall} data set they find the global minimum, not the local one.

Both bundle algorithms perform rather badly compared to the MATLAB routines. Although the bundle algorithms can use subgradient information which the MATLAB routines lack.
It can be observed, that for the \texttt{synsmall} data set, the bundle methods solve the task faster, but the solutions are not as exact as the ones obtained by the MATLAB solvers.
For the \texttt{synbig} data set, all algorithms need considerably more time solving the optimization problem than for the other data sets.
A reason for this is, that the lower level problem needs more solution time due to its increased size.
As also the adjoint problem increases in size (the constraints of both, the lower level and the adjoint problem, scale with the number of data points) the bundle methods need more time solving the bilevel program.
It can be seen, that the approach to find the subgradient via the adjoint problem is not appropriate for larger data sets.

The bundle algorithms \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1 show similar results in terms of computation time. Here the second order information used by algorithm \ref{sec_variable_metric}.1 has no measurable influence.
Both algorithms reach an accuracy of about \(10^{-3}\) of the minimizer compared to the MATLAB routines. The accuracy of the optimal found function value lies around \(10^{-4}\) for the objective scaled with 100 if a correct minimizer is found.


%. Algorithm  \ref{sec_nonconv_inex}.1 needs slightly less steps and therefore also less time than algorithm  for most of the optimization tasks. Still the values are comparable. 
%The method \ref{sec_variable_metric}.1 is a bit more stable in the results for the minimizer \(C_{min}\). 

%For the objective function scaled with 100 both bundle algorithms stop less often after the first step. On the other hand for this scaling it occurs tree times, that a bundle algorithm stops due to the number of steps. This does not happen with the unscaled objective.

The convexification parameter \(\eta_k\) is assumed to stay bounded in \cite[p. 11]{Hare2016}. Although all of the objective functions have a ``generally convex'' form, the maximum \(\eta_k\) occurring in the algorithms is of order \(10^{6}\). Generally \(\eta_k\) seems to reach higher values for the scaled objective function as it can be seen in Table \ref{scal_100_ll15}.

It is now tested, if a lower stopping tolerance of the bundle methods can increase their accuracy.
For this experiment only the starting value \(C_0 = 1\) and the scaled objective function are taken.
The lower level and adjoint problems are still solved to an accuracy of \(10^{-15}\). The accuracy of the overall method is increased from \(10^{-6}\) to \(10^{-10}\).

Interestingly it can be observed, that for algorithm \ref{sec_nonconv_inex}.1 the minimizer that is found by the algorithm only changes for the \texttt{synbig} data set. For all other sets, the exact same results are found.
This is not the case for method \ref{sec_variable_metric}.1. Here better results are found for the data sets \texttt{synbox}, \texttt{synsmall} and \texttt{synbig}.
However the effective accuracy of the function value does not change compared to the case when the stopping tolerance is \(10^{-6}\). The extra computation time needed for the more exact case is comparatively low.
We conclude from that, that for most of the data sets the calculations of both methods (\ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1) are already much below the tolerance of \(10^{-6}\) when the algorithms stop. This means, that no, or only a few more calculations are  needed to meet also a smaller stopping tolerance.
All in all these insights suggest, that it is not possible, to achieve as exact solutions of the bilevel problems as the MATLAB procedures do with the bundle algorithms, even if the stopping tolerance is lowered.
%For an accuracy of \(10^{-7}\) there is almost no difference to the results from above. The bundle algorithms need up to one step more for the smaller data sets and up to four steps more for the \texttt{synbig} set to reach the desired tolerance. For the latter set the difference in the minimal \(C\) is of order \(10^{-2}\), but the resulting difference in the function value amounts only to \(10^{-8}\).
%The results in \(C\) and the function value are exactly the same for the smaller dater sets. 

Finally the performance of the methods for different levels of accuracy is tested.
To do this, algorithms \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1 run with the lower level and adjoint problem only solved inaccurately.
The different tolerances that are used are \(10^{-4}\) and \(10^{-8}\)  

\begin{figure}[ht]
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{Pictures/Plots/Scal100_llad-8C.eps}%
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{Pictures/Plots/Scal100_llad-4C.eps}%
	\end{subfigure}
	\caption[Minimizer for different stopping tolerances of the lower level and adjoint program]{The Plots show the minimizers that are found for different stopping tolerances of the adjoint and lower level program.\\
	The black bar over each set shows the result that is achieved with the \textup{\texttt{fminbnd}} method if the lower level problem is solved to a tolerance of \(10^{-15}\). The pink stem shows the result of \textup{\texttt{fminbnd}} for a tolerance of the lower level of \(10^{-8}\) in the left plot and \(10^{-4}\) in the right plot. The four following stems for each data set show the results of the combinations (from left to right): Lower level and adjoint problem solved for tolerance \(10^{-15}\); lower level solved for \(10^{15}\), adjoint for \(10^{-8}, 10^{-4}\); lower level solved for \(10^{-8},10^{-4}\) adjoint for \(10^{-15}\); lower level and adjoint problem solved for \(10^{-8},10^{-4}\)\\
	The first three data sets are measured with the scale on the left, the other two data sets with the scale on the right.}%
	\label{fig_llad84C}%
\end{figure}

\begin{figure}[ht]
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{Pictures/Plots/Scal100_llad-8f.eps}%
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{Pictures/Plots/Scal100_llad-4f.eps}%
	\end{subfigure}
	\caption[Minimal value for different stopping tolerances of the lower level and adjoint program]{The Plots show the minimial function values that are found for different stopping tolerances of the adjoint and lower level program.\\
	The black bar over each set shows the result that is achieved with the \textup{\texttt{fminbnd}} method if the lower level problem is solved to a tolerance of \(10^{-15}\). The pink stem shows the result of \textup{\texttt{fminbnd}} for a tolerance of the lower level of \(10^{-8}\) in the left plot and \(10^{-4}\) in the right plot. The four following stems for each data set show the results of the combinations (from left to right): Lower level and adjoint problem solved for tolerance \(10^{-15}\); lower level solved for \(10^{15}\), adjoint for \(10^{-8}, 10^{-4}\); lower level solved for \(10^{-8},10^{-4}\) adjoint for \(10^{-15}\); lower level and adjoint problem solved for \(10^{-8},10^{-4}\).\\
	The first three data sets are measured with the scale on the left, the other two data sets with the scale on the right.}%
	\label{fig_llad84f}%
\end{figure}

The other parameters are set in a way that achieved good results in the comparison before.
Precisely this means that the objective function is scaled by 100 and the bundle methods start with value \(C_0 = 1\). 
The found minimizers and minimal function values for the different combination of tolerances are depicted in figures \ref{fig_llad84C} and \ref{fig_llad84f} respectively.

What can be seen is, that the solution tolerance of the adjoint problem does not show any influence on the accuracy of the bundle algorithms. The minimizer and the function value basically stay the same, no matter if the adjoint problem is solved for an accuracy of \(10^{-4}\), \(10^{-8}\) or \(10^{-15}\).
The reason for this is, that the adjoint problem calculates the subgradient. It could already be seen in section \ref{sec_num_test_ferr}, that inexactness of the subgradient has a relatively small influence on the overall solution.

The plots also show, that the solution accuracy of the lower level can have big influence on the value of the minimizer. This is also true for the results found by \texttt{fminbnd}.
This results from the little change in the objective function values. It can be observed, that although the value of the minimizer is sometimes far away from the correct one, the resulting function value is still near the optimum.

The final step of this analysis of the one-dimensional case is to study how much the 'worse' results of the bundle methods actually influence the generalization ability of the optimal model.
This is tested by calculating the misclassification error on the validation sets of the \texttt{cancer} and \texttt{ionosphere} data.
Therefore, an optimal separating hyperplane \(\tilde{w}\) is calculated, given the optimal hyper-parameter \(C_{min}\). For this calculation all training data is used. The hyper-parameter has to be scaled by \(\frac{T}{T-1}, T >1\) \cite[p. 47]{Kunapuli2008} for the use with only one fold. 
As mentioned before, we use the misclassification loss as given in (\ref{misclass_loss}) to calculate the fraction of the data that is misclassified.
%This result is compared to the minimal possible linear misclassification error on the validation data set.

\begin{table}%
\centering
\begin{tabular}{|l|c|c|c|}
	\hline
	Data set & Bundle \ref{sec_nonconv_inex}.1 & Bundle \ref{sec_variable_metric}.1 & \texttt{fminbnd}\\
	\hline
	\texttt{cancer} & 0.038374 & 0.038374 & 0.038374 \\
	\texttt{ionosphere} & 0.153153 & 0.162162 & 0.162162 \\
	\hline
\end{tabular}
\caption[Misclassification error for 1D data]{Misclassification error on the validation data. The separating hyperplane is generated using the \(C_{min}\) value found by the respective optimization algorithm.}
\label{misclass_1D}
\end{table}

One can see, that the SVM problem itself is not too sensitive to the choice of the hyper-parameter.
This means, that despite the fact, that the MATLAB routines provide better results in numbers, the bundle methods find an equally good hyperplane.

To summarize this section it can be said, that in the one-dimensional case, the MATLAB routines outperform the bundle methods. The algorithm \texttt{fminbnd} finds very accurate results, often in less time than the bundle methods. Additionally it does not need a starting value.
We can conclude, that in the one-dimensional case, the bundle algorithms work for solving the presented problem, but there are better options available.

\subsubsection{Multi-dimensional Optimization}

In the multigroup approach, the data set is partitioned into different groups, that are each weighted with their own parameter \(C_g\).
To calculate the optimal value of all these parameter results in a multi-dimensional optimization problem.

In this section the bundle algorithms \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1 are compared to the matlab method \texttt{fmincon}. This method is suitable for the solution of a very wide range of constrained multi-dimensional optimization problems. They can be nonlinear and do not have to be convex.

The following data sets are used for the comparison:

\begin{table}[H]%
\centering
\begin{tabular}{|lcccc|}
	\hline
	Data set & \(n_d\) & \(n_f\) & T & G \\
	\hline
	\texttt{cancer1} & 960 & 9 & 3 & 4\\
	\texttt{cancer2} & 678 & 9 & 3 & 2\\
	\texttt{cancer3} & 678 & 9 & 3 & 2\\
	\texttt{cancer4} & 675 & 9 & 3 & 3\\
	\texttt{ionospere1} & 960 & 33 & 3 & 4\\
	\texttt{ionosphere2} & 348 & 33 & 3 & 2 \\
	%\texttt{synsmall1} & 1800 & 2 & 2 & 3 \\
	%\texttt{synbox1} & 2400 & 2 & 4 & 3 \\
	\hline
\end{tabular}
\caption[Properties of the data sets for multi-dimensional optimization]{Properties of the data sets for multi-dimensional optimization.}
\label{}
\end{table}

They are constructed in the following ways:
The sets \texttt{cancer1}, and \texttt{ionosphere1} are constructed by duplicating the original data sets \(G\) and adding different amounts of uniformly distributed noise on the data of the different groups.
The sets \texttt{cancer2}, \texttt{cancer3}, \texttt{cancer4} and \texttt{ionosphere2} are constructed by using also the validation data of the original data sets and partitioning it  randomly in \(G\) groups of equal size.
For the \texttt{cancer2} data set, there is additionally noise added to the second group.

First the multigroup bilevel problem is solved by the three algorithms \texttt{fmincon}, \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1 for all data sets. The objective function is again scaled by 100. The stopping conditions are meeting the stopping tolerance \texttt{tol} \(=10^{-6}\) and exceeding the maximal number of steps (1000).
All subproblems are calculated to a  tolerance of \(10^{-10}\).
The starting values for the different dimensions are set to 
\(C_{0,2} = (5,0.5)^{\top}\), \(C_{0,3} = (5,0.5,0.05)^{\top}\) and \(C_{0,4} = (5,0.5,0.05,1)^{\top}\). 

Table \ref{tab_MG} show the results for the different algorithms.

\begin{table}[ht]%
\centering
\begin{tabular}{|l|c|c|c|c|}
	\hline
	Data set & & Bundle \ref{sec_nonconv_inex}.1 & Bundle \ref{sec_variable_metric}.1 & \texttt{fmincon} \\
	\hline
	\texttt{cancer1} & \(C_{min}\) & \(\begin{pmatrix}0.1525\\1.01\cdot10^{-5}\\10^{-5}\\4.5948\end{pmatrix}\) & \(\begin{pmatrix}0.1642\\10^{-5}\\10^{-5}\\5.5829\end{pmatrix}\) & \(\begin{pmatrix}0.3149\\0.5369\\1.3596\\8.22\cdot10^{3}\end{pmatrix}\) \\
	& \(f\) value & 49.7412 & 49.7381 & 49.7105\\
	& time (s) & 23 & 16 & 146\\ 
	\hline
	\texttt{cancer2} & \(C_{min}\) & \(\begin{pmatrix}10^{-5}\\0.0421\end{pmatrix}\) & \(\begin{pmatrix}0.0714\\1.06\cdot10^{-4}\end{pmatrix}\) & \(\begin{pmatrix}0.0693\\0.0259\end{pmatrix}\) \\
	& \(f\) value & 10.7188 & 10.2587 & 10.1394\\
	& time (s)& 5 & 7 & 9\\
	\hline
	\texttt{cancer3}& \(C_{min}\) & \(\begin{pmatrix}0.0389\\0.0573	\end{pmatrix}\) & \(\begin{pmatrix}0.0550\\0.0165\end{pmatrix}\) & \(\begin{pmatrix}0.0555\\0.0386\end{pmatrix}\) \\
	& \(f\) value & 11.3871 & 11.4340 & 11.3438\\
	& time (s)& 71 & 9 & 15\\
	\hline
	\texttt{cancer4}& \(C_{min}\) & \(\begin{pmatrix}0.0476\\0.2342\\0.1778\end{pmatrix}\) & \(\begin{pmatrix}0.0219\\0.0829\\0.0679\end{pmatrix}\) & \(\begin{pmatrix}0.0202\\0.0771\\0.0642\end{pmatrix}\) \\
	& \(f\) value & 9.8094 & 9.6319 & 9.6308\\
	& time (s)& 134 & 27 & 16\\
	\hline
	\texttt{ionosphere1}& \(C_{min}\) & \(\begin{pmatrix}0.0078\\0.0169\\0.0282\\10^{-5}\end{pmatrix}\) & \(\begin{pmatrix}10^{-5}\\0.0478\\10^{-5}\\10^{-5}\end{pmatrix}\) & \(\begin{pmatrix}0.0074\\0.0455\\10^{-5}\\10^{-5}\end{pmatrix}\) \\
	& \(f\) value & 44.1661 & 46.6613 & 44.0434\\
	& time (s)& 246 & 7 & 59\\
	\hline
	\texttt{ionosphere2}& \(C_{min}\) & \(\begin{pmatrix}0.0116\\0.0189\end{pmatrix}\) & \(\begin{pmatrix}10^{-5}\\0.0215\end{pmatrix}\) & \(\begin{pmatrix}0.0116\\0.0189\end{pmatrix}\) \\
	& \(f\) value & 47.3260 & 49.7165 & 47.3260\\
	& time (s)& 10 & 4 & 9\\
	\hline
	%\texttt{synsmall1}& \(C_{min}\) & \(\begin{pmatrix}0.4011\\1.01\cdot10^{-5}\\1.01\cdot10^{-5}\end{pmatrix}\) & \(\begin{pmatrix}0.3872\\10^{-5}\\10^{-5}\end{pmatrix}\) & \(\begin{pmatrix}0.4027\\1.03\cdot10^{-5}\\1.03\cdot10^{-5}\end{pmatrix}\) \\
	%& \(f\) value & \\
	%& time (s)& \\
	%\hline
	%\texttt{synbox1}& \(C_{min}\) & \(\begin{pmatrix}0.0257\\4.1791\\3.7443\end{pmatrix}\) & \(\begin{pmatrix}0.0178\\4.2698\\3.7326\end{pmatrix}\) & \(\begin{pmatrix}0.0227\\0.1696\\1.42\cdot10^{-5}\end{pmatrix}\) \\
	%& \(f\) value & \\
	%& time & \\
	%\hline
\end{tabular}
\caption[Minimizer, function value and computation time for the multigroup problem]{This table shows the minimizer, corresponding minimal function value and the needed computation time of the three tested routines \textup{\texttt{fmincon}}, algorithm \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1.\\
The used objective function is scaled with 100.}
\label{tab_MG}
\end{table}

It can be seen, that again the MATLAB routine \texttt{fmincon} reaches the lowest function values. However often the computation time is also longer than the ones of the two bundle methods.
An interesting fact is, that the various found minimizers are very different from each other.
This might be due to the flat shape of the objective functions, which can be observed in the two-dimensional case.
However, scaling the objective function with higher numbers gives even worse results for the bundle methods.
For the sets \texttt{cancer1}, \texttt{cancer3} and \texttt{ionosphere1} it can not be detected, that the groups with the added noise are weighted consistently lower, than the exact group.

The function values decrease for the bundle methods if the subproblem is solved to a higher accuracy (here \(10^{-15}\)). For \texttt{fmincon} this effect is barely measurable. 
However, the computation time is about doubled for \texttt{fmincon} in that case, whereas it does not rise for the bundle algorithms.
This indicates, that in the nearly exact case, the bundle algorithm may profit from the subgradient information.
Like in the one-dimensional case, it does not influence the results if the adjoint problem is computed to a lower tolerance.
The same holds true if the stopping tolerance is lowered.
This is as expected, since the same behavior can also be seen in the one-dimensional case.

We remark that the parameter \(\eta_k\) reaches high values up to \(10^8\) for both bundle methods.

As in the one-dimensional case we close this analysis by comparing how well the generated models work on unseen data.
Therefore we compute the optimal hyperplanes, given the optimal hyper-parameters \(C_{min}\), on the whole set of training data.
Then this hyperplane is used to classify the validation set and the numbers of misclassified points are compared.
The hyper-parameters are scaled in the same way as above to compensate for using only one fold.

\begin{table}[ht]%
\centering
\begin{tabular}{|l|c|c|c|}
	\hline
	Data set & Bundle \ref{sec_nonconv_inex}.1 & Bundle \ref{sec_variable_metric} & \texttt{fmincon} \\
	\hline
	\texttt{cancer1} & 0.038374 & 0.038374 & 0.036117\\
	\texttt{cancer2} & 0.027088 & 0.033860 & 0.031602\\
	\texttt{cancer3} & 0.029345 & 0.029345 & 0.029345\\
	\texttt{cancer4} & 0.027088 & 0.029345 & 0.0293453\\
	\texttt{ionosphere1} & 0.198198 & 0.216216 & 0.198198\\
	\texttt{ionosphere2} & 0.144144 & 0.135135 & 0.144144\\
	\hline
\end{tabular}
\caption[Misclassification error for multi-dimensional data]{Misclassification error on the validation data. The separating hyperplane is generated using the \(C_{min}\) value found by the respective optimization algorithm.}
\label{misclass_mD}
\end{table}

Again it can be observed, that the variance in the hyper-parameter does not result in an equally board variance of the misclassification error.

All in all, we conclude that again both bundle algorithms, \ref{sec_nonconv_inex}.1 and \ref{sec_variable_metric}.1, are able to solve the given bilevel problem.
The minimizers, that are found by the various algorithms, are very different. Still the computed loss function values are close together. The \texttt{fmincon} routine is able to generate the lowest function values.
The bundle algorithms can compare to the computation time of the MATLAB algorithm and for very accurately calculated inner level problems, they outperform \texttt{fmincon} in terms of computation time.
%A possible reason for this could be the special form of the objective functions, which is really flat with very high peaks or edges.


%The computation time becomes lower as the tolerances increase, because the subproblems take less time to be computed.
%It can be seen, that method \ref{sec_nonconv_inex}.1 is generally a bit slower, than method \ref{sec_variable_metric}.1.


%For all algorithms the accuracy to which the lower level problem is solve is \textcolor{red}{accuracy/accuracies???} for the constraints and optimality. For the bundle algorithm the adjoint problem is solved with an accuracy of \textcolor{red}{accuracy/accuracies???}.
%\textcolor{red}{Maybe look-out on what happens if different accuracies are used.}

%\textcolor{red}{Weglassen? (ganze Funktion?)\\
%Note that the \texttt{fminsearch} method cannot be provided with any bounds. This means, that when optimizing the given bilevel problem with this method, nonpositive values for \(C\) can occur which is not allowed in theory. This happend however in none of the tests done in this thesis.}.





%Parameters of the algorithms:
%\begin{itemize}
	%\item stopping condition bundle algo: \(10^{-?}\) or steps: 
	%\item stopping lower level: 
	%\item stopping adjiont problem:
	%\item starting points
	%\item scaling of the objective function
%\end{itemize}
%
%
%\subsubsection{???}
%
%
%
%\textcolor{red}{Ergebnisse in Tabellenform und beschreiben, was man sieht\\
%description of starting values and remark that \texttt{fminbnd} does not need a starting value}



%
%In this section algorithm \ref{sec_nonconv_inex}.1 is used to solve the bilevel problems presented above for different synthetic and real world data sets.
%
%\begin{itemize}
	%\item Problem what to optimize
	%\item comment on nonlinear 
	%\item overfitting
	%\item pictures that show situation
%\end{itemize}
%
%
%\subsubsection{Selection of the Data Sets}
%
%\begin{itemize}
	%\item parameter \(\lambda\) against overfitting, there to make generalization better
	%\item data sets that ``allow'' for high overfitting: not too big, many features
%\end{itemize}
%
%
%
%\textbf{Gliederung:}\\
%Einleitung\\
%%Datensaetze beschreiben\\
%%erklaerung welche Art von Datensaetzen sinnvoll waere und dass nichtlineare Trennung ``besser'' -> mit Bildern von Daten und optimalem w???\\
%was genau gemacht wurde (worauf gerechnet, Zielfunktionen,...) 
%-> mit bildern der Zielfunktionen (Plots)\\
%Auswertung als Tabellen


%
%Plots
%Plots, that I want (red) / have (green)\\
%\textcolor{green}{Plots der Monogroup Datensaetze\\
%plot von Box?SynSmall? mit w um Spezifisches zu zeigen fuer sinnvolle regularisierung}\\
%\textcolor{red}{plot mit zwei gruppen ?}





%results
%\textcolor{red}{Hinweise: fminbd ohne Startwert\\
%wie Funktionen funktionieren\\
%boundaries etc...\\
%suche bei plots noch mal min genauer raus \\
%beste Darstellungen ueberlegen}

%\begin{table}%
%\begin{tabular}{|l|c|c|c|c|c|}
	%\hline
	%Data set & \(C_0\) & Bundle \ref{sec_nonconv_inex}.1 & Bundle \ref{sec_variable_metric}.1 & \texttt{fminsearch/bnd} \\
	%\hline
	%\texttt{cancer} & \(10^{-5}\) & 0.0601 & 0.0607 & 0.0604 \\
		%& 0.01 & 0.0601 & 0.0602 &  \\
		%& 1 & 0.0604 & 0.0604 &  \\
		%& 20 & 0.0606 & 0.0600 &  \\
		%& 100 & 100 & 100 &  \\
		%\hline
	%\texttt{ionosphere} & \(10^{-5}\) & \(10^{-5}\) & \(10^{-5}\) & 0.0236 \\
		%& 0.01 & 0.0235 & 0.0237 & \\
		%& 1 & 0.0245 & 0.0236 &  \\
		%& 20 & 0.0246 & \(10^{-5}\) &  \\
		%& 100 & \(10^{-5}\) & \(10^{-5}\) & \\
		%\hline
	%\texttt{synbox} & \(10^{-5}\) & \(10^{-5}\) & \(10^{-5}\) &  \\
		%& 0.01 & 0.0135 & 0.0135 &  \\
		%& 1 & 0.0160 & 0.0135 &  \\
		%& 20 & 20 & 20 &  \\
		%& 100 & 100 & 100 &  \\
		%\hline
	%\texttt{synsmall} & \(10^{-5}\) & 5.0215 & 4.8053 & 6.6372 \\
		%& 0.01 & 4.7123 & 4.9525 &  \\
		%& 1 & 4.8286 & 5.0210 &  \\
		%& 20 & 20 & 20 &  \\
		%& 100 & 100 & 100 &  \\
		%\hline
	%\texttt{synbig} & \(10^{-5}\) & \(10^{-5}\) & \(10^{-5}\) & 16.4595 \\
		%& 0.01 & 11.8456 & 12.0395 &  \\
		%& 1 & 1 & 1 &  \\
		%& 20 & 20 & 20 &  \\
		%& 100 & 100 & 100 &  \\
		%\hline
%\end{tabular}
%\caption[]{C, scal 1}
%\label{}
%\end{table}


%\begin{table}%
%\begin{tabular}{|l|c|c|c|c|c|}
	%\hline
	%Data set & \(C_0\) & Bundle \ref{sec_nonconv_inex}.1 & Bundle \ref{sec_variable_metric}.1 & \texttt{fminsearch/bnd} \\
	%\hline
	%\texttt{cancer} & \(10^{-5}\) &  0.1196 & 0.1196 & 0.1196\\
		%& 0.01 &  0.1196 & 0.1196 & \\
		%& 1 &  0.1196 & 0.1196& \\
		%& 20 &  0.1196  & 0.1196&\\
		%& 100 &  1.0041  & 1.0041& \\
		%\hline
	%\texttt{ionosphere} & \(10^{-5}\) & 0.9942 & 0.9942 & 0.4352\\
		%& 0.01 & 0.4352 & 0.4352 & \\
		%& 1 & 0.4353 & 0.4352 &\\
		%& 20 &  0.4353 & 0.9942 &\\
		%& 100 & 0.9942 & 0.9942&\\
		%\hline
	%\texttt{synbox} & \(10^{-5}\) & 0.9942 & 0.9942 & 0.5171\\
		%& 0.01 & 0.5171 & 0.5171&\\
		%& 1 & 0.5176 & 0.5171&\\ 
		%& 20 & 0.7103 & 0.7103&\\
		%& 100 &  0.7116 & 0.7116&\\
		%\hline
	%\texttt{synsmall} &  \(10^{-5}\) & 0.0165 & 0.0165&0.0165\\
		%& 0.01 &  0.0165 & 0.0165 &\\
		%& 1 &  0.0165 & 0.0165 &\\
		%& 20 &  0.0197 & 0.0197 &\\ 
		%& 100 &  0.0335 & 0.0335&\\
		%\hline
	%\texttt{synbig} & \(10^{-5}\) & 0.6283 & 0.6283&1.9261\cdot\(10^{-4}\) \\
		%& 0.01 & 1.9487\cdot\(10^{-4}\) & 1.9466\cdot\(10^{-4}\) & \\
		%& 1 & 3.5143\cdot\(10^{-4}\) & 3.5143\cdot\(10^{-4}\) &\\
		%& 20 & 1.9348\cdot\(10^{-4}\) & 1.9348\cdot\(10^{-4}\)& \\
		%& 100 & 2.6452\cdot\(10^{-4}\) & 2.6452\cdot\(10^{-4}\)& \\
		%\hline
%\end{tabular}
%\caption[]{fval, 1}
%\label{}
%\end{table}

%times
%
%\begin{center}
%\begin{table}[H]%
	%\begin{tabular}{llcccc}
		%\hline
    %Data set & algorithm & 0.1 & 1 & 10 & 100 \\
		%\hline
		%\texttt{syn big} & Bundle Noll & 202 & 320 & 386 & 503 \\
		 %& fminsearch & 672 & 637 & 587 & 741 \\
		 %& fminbnd & 557
	%\end{tabular}
	%\caption{}
%\end{table}
%\end{center}
%
%sometimes says problem not convex, then negative values. Why??? Because tries negative lambda values in course of optimization and then it gets negative \\
%sometimes even for negative lambda in the end right solution \\
%can I find out why bundle methods so bad? \\
%try matlab method (smooth) with subgradient???
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsubsection{Solution of the Bilevel Program}
%
%\textcolor{red}{ab hier: Theorie fehlt\\
%!!! notation - oder in prelininaries einfugen}
%%ingredients for bundle method
%
%To solve the given bilevel problem with the above presented nonconvex inexact bundle algorithm the algorithm jumps between the two levels. Once the inner level problems are solved for a given \(\lambda\) - this is possible with any QP-solver as the problems are convex - the bundle algorithm takes the outcome \(w\) and \(b\) and optimizes the hyper-parameter again.
%
%The difficulty with this approach is that the bundle algorithm needs one subgradient of the outer level objective function with respect to the parameter \(\lambda\). However to compute this subgradient also one subgradient of \(w\) and \(b\) with respect to \(\lambda\) has to be known.
%
%\textbf{The Differentiable Case}
%\textcolor{red}{example in differentiable case}\\
%Let us first assume that the outer and inner objective functions and \(w(\lambda)= \argmin \mathcal{L}_{low}(w,\lambda)\) are sufficiently often continuously differentiable to demonstrate the procedure of calculating the needed {(sub-)gradients}.
%
%Let \(\mathcal{L}_{upp}(w,\lambda)\) be the objective function of the outer level problem, where the variable \(b\) was left out for the sake of simplicity.
%To find an optimal hyper parameter \(\lambda\) given the input \(w\) the gradient \(g^{upp}_{\lambda}\) of \(\mathcal{L}_{upp}\) with respect to \(\lambda\) is needed in every iteration of the solving algorithm.
%In order to calculate this gradient the chain rule is used yielding
%
%\begin{equation*}
	%g^{upp}_{\lambda} = \left(\frac{\partial}{\partial w}\mathcal{L}_{upp}(w,\lambda) \right)^{\top}\frac{\partial w(\lambda)}{\partial\lambda}+\frac{\partial}{\partial \lambda}\mathcal{L}_{upp}(w,\lambda).
%\end{equation*}
%
%The challenge is here to find the term \(\frac{\partial w(\lambda)}{\partial\lambda}\) because 
%
%\[ \frac{\partial w}{\partial \lambda} \in \frac{\partial }{\partial \lambda} \argmin_{w} \mathcal{L}_{low}(w,\lambda). \]
%
%Assuming \(\mathcal{L}_{low}\) is twice continuously differentiable at the  optimal solution \(w^*\) of the lower level problem the optimality condition for any parameter \(\lambda_0 > 0\)
%
%\begin{equation}
	%0 = \frac{\partial}{\partial w}\mathcal{L}_{low}(w^*,\lambda_0)
%\label{opt_con}
%\end{equation}
%
%
%can be used to calculate the needed gradient in an indirect manner.
%
%In the differentiable case the theoretical framework for the following calculations is given by the implicit function theorem.
%
%\begin{theorem}[{c.f. \cite[chapter 3.4]{Koenigsberger2002}}]
	%Let \(F: U \times V \to Z \), \(U\in\R^m, V,Z\in \R^n \), be a \(\mathcal{C}^1\) mapping, \((x_0,y_0) \in U\times V\)  and \(F(x_0,y_0) = 0\). If the matrix \(\frac{\partial}{\partial y}F(x_0,y_0)\) is invertible, there exist neighborhoods \(U_0\subset U\) of \(x_0\) and \(V_0\subset V\) of \(y_0\) and a continuously differentiable mapping \(f:U_0 \to V_0\) with 
	%\begin{equation*}
	%F(x,y) = 0, (x,y)\in U_0\times V_0  \quad \Leftrightarrow \quad y = f(x), x\in U_0.
	%%\label{imp_fun_theo}
	%\end{equation*}
%\end{theorem}
%
%Identifying \(x \estimates \lambda\), \(y \estimates w\) and  \(F(x_0,y_0) \estimates \frac{\partial}{\partial w} \mathcal{L}_{low}(w^*,\lambda_0)\) and assuming \(\frac{\partial^2 }{\partial  w^2}\mathcal{L}_{low}(w^*,\lambda_0)\) is invertible this theorem provides the existence of the continuously differentiable function \(w(\lambda)\) whose gradient is needed. \\
%\textcolor{red}{what about the neighborhoods?}
%
%If the inner level loss function yields a linear optimality condition in \(w\) it is possible to calculate the gradient explicitly. This is for example the case for SVM loss functions with a squared one- or two-norm as given in problem (\ref{SVM_2}).
%The optimality condition can then be written as the linear system
%
%\begin{equation*}
	%H(\lambda)w = h(\lambda).
%\end{equation*}
%
%By taking the partial derivative with respect to \(\lambda\) on both sides of the system one gets
%
%\begin{equation*}
	%\frac{\partial H(\lambda)}{\partial \lambda}w+H(\lambda)\frac{\partial w}{\partial \lambda} = \frac{\partial h(\lambda)}{\partial  \lambda}.
%\end{equation*}
%
%If \(H(\lambda)\) is invertible for all \(\lambda \in \Lambda\) then the needed gradient is given by 
%
%\begin{equation*}
	%\frac{\partial w}{\partial \lambda} = H^{-1}(\lambda)\left(\frac{\partial h(\lambda)}{\partial \lambda}-\frac{\partial H(\lambda)}{\partial \lambda}w\right).
%\end{equation*}
%
%%\textcolor{red}{why H invertible??? - because we assume existence of \(w\)???}\\
%
%\textbf{The Nondifferentiable Case}
%\textcolor{red}{now for subgradients}
%
%In practice we cannot expect \(\mathcal{L}_{low}\) to satisfy such strong differentiability properties.
%It is therefore only assumed that \(\mathcal{L}_{low}\) is once continuously differentiable in \(w\). This assures that the optimality condition of the lower level problem is an equality like in (\ref{opt_con}).
%%If \(\mathcal{L}_{low}\) was only locally Lipschitz the optimality condition states that zero is part of the subgradient set  \(\partial \mathcal{L}_{low}(w^*,\lambda_0)\).  
%Contrary to the exemplary calculations from above in practice the second derivative \(\frac{\partial^2}{\partial w \partial \lambda} \mathcal{L}_{low}(w(\lambda),\lambda)\) however is not existent in this form, but a set of subgradients.
%
%
%
%\textcolor{red}{\textbf{Notation}}\\
%First the theoretical framework given to derive the results from above in the nondifferentiable case
%
%
%
%\textcolor{red}{An important result about Lipschitz functions is Rademacher's theorem which states that these functions are differentiable almost everywhere but on a set of Lebesgue measure zero\cite[Theorem 3.1]{Heinonen2004}. 
%Clarke deduces from this that the subdifferential at each of the nondifferentiable points is the convex hull of the limits of the sequence gradients a these points \cite[see Theorem 2.5.1]{Clarke1990}.}
%
%This motivates the multidimensional definition of Clake's generalized gradient 
%
%\textcolor{red}{
%\begin{definition}[{\cite[Definition 2.6.1]{Clarke1990}}]
	%\emph{generalized Jacobian}: \(F:\R^n \to \R^m\), with locally Lipschitz component functions \(F(x) = (f_1(x),...,f_m(x))\).\\
	%Denote generalized Jacobian by \(\partial F(x) = conv\left(\lim JF(x_i)|x_i\to x, x_i \notin \Omega_F \right) \) where \(\Omega_F\) is the set of nondifferentiable points of \(F\)
%\end{definition}
%(after that comes proposition with properties of \(\partial F\))}
%
%
%\textcolor{red}{To facilitate readability we use the following notation for the derivation of the nondifferentiable results.}
%
%The \emph{'partial' subdifferential} of a function \(f(a^*,b_0,c_0,...)\) at the point \(a^*\) with respect to one variable \(a\) when all other variables are fixed is denoted by 
%\begin{equation*}
	%\partial^{a} f(a^*,b_0,c_0,...).
%\end{equation*}
%
%A subgradient of this subdifferential is written \(g^{a} \in \partial^{a} f(a^*,b_0,c_0,...)\).
%
%Next step: show that chain rule is still valid in the nonsmooth case
%Chain rules for subdifferential \\
%
%\begin{theorem}[{\cite[Theorem 2.6.6]{Clarke1990}}]
	%Let \(f(x)=\phi(F(x))\), with the locally Lipschitz functions \(F: \R^n \to \R^m\) and \(\phi:\R^m \to \R\). Then \(f\) is locally Lipschitz and it holds
	%\begin{equation*}
		%\partial f \subset \text{conv}\left\{\partial \phi(F(x))\partial F(x)\right\}.
	%\end{equation*}
	%If in addition \(\phi\) is strictly differentiable at \(F(x)\), then equality holds.
%\end{theorem}
%
%\textcolor{red}{strictly differentiable: c.f. \cite[Theorem 9.17 and 9.18]{Rockafellar2009} locally Lipschitz continuous and at most one subgradient at the point in question (see also comment to Definition 91 in \cite{Rockafellar2009})}
%
%\begin{theorem}[c.f. {\cite[Theorem 7.1]{Rockafellar1985}}]
	%Let \(p(x) = f(F(x))\), where \(F:\R^n \to \R^d\) is locally Lipschitz and \(f:\R^d \to \R\) is lower semicontinuous. 
	%Assume \[\nexists y \in \partial^{\infty}f(F(\bar{x})), y \neq 0 \quad \text{with} \quad 0 \in y \partial F(\bar{x}). \]
	%Then for the sets 
	%\[ M(\bar{x}):= \partial f(F(\bar{x}))\partial F(\bar{x}), \quad M^{\infty}(\bar{x}):= \partial^{\infty}f(F(\bar{x}))\partial F(\bar{x}), \]
	%one has \(\hat{\partial}p(\bar{x}) \subset M(\bar{x})\) and \(\hat{\partial}^{\infty} p(\bar{x}) \subset M^{\infty}(\bar{x})\).
%\end{theorem}
%
%The main idea is to replace the inner level problem by its optimality condition
%
%
%\(\partial(w,b)\) means in this case that the subdifferential is taken with respect to the variables \(w\) and \(b\). \\
%-> theory for subdifferentials in more than one variable!!! \\
%
%For convex inner level problem this replacement is equivalent to the original problem.
%
%The difference to the approach described in \cite{Kunapuli2008} is that the problem is not smoothly replaced by its KKT conditions but only by this optimality condition. The weight vector \(w\) and bias \(b\) are treated as a function of \(\lambda\) and are optimized separately from this hyper-parameter.
%The reformulated bilevel problem becomes:
%
%\begin{align}
	%\begin{split}
	%\min_{w,\bm{b}} \quad &  \mathcal{L}_{hinge}(w,\bm{b}) = \frac{1}{T}\sum_{t=1}^T\frac{1}{|\mathcal{N}_t|}\sum_{i \in \mathcal{N}_t}{\max\left(1-y_i((w^t)^{\top}x-b_t),0\right)}\\
	%\text{subject to} \quad & \lambda > 0 \\
	%& \text{for } t = 1,...,T \\
	%& 0 \in \partial(w,b)\mathcal{L}_{low}(\lambda,w^t,b_t) \\
%\end{split}
%\label{SVM_opt_cond}
%\end{align}
%
%where \(\mathcal{L}_{low}\) can be the objective function of either of the two presented lower level problems.
%
%
%
%solve the inner level problem (quadratic problem in constrained case) by some QP solver \\
%put solution into upper level problem and solve it by using bundle method \\
%difficulty: subgradient is needed to build model of the objective function --> need subgradient \(\frac{\partial \mathcal{L}}{\partial \lambda}\) --> for this need \(\frac{\partial (W,b)}{\partial \lambda}\) \\
%but \((w,b)\) not available as functions -> only values
%
%Moore et al. \cite{Moore2011} describe a method for getting the subgradient from the KKt-conditions of the lower level problem:
%
%lower level problem convex -> therefore optimality conditions (some nonsmooth version -> source???) necessary and sufficient -> make ``subgradient'' of optimality conditions and then derive subgradient of w, b from this. \\
%---> what are the conditions? optimality condition Lipschitz? 
%
%Say (show) that all needed components are locally Lipschitz; state theorems about differentiability almost everywhere and convex hull of gradients gives set of subgradients\\
%introduce special notation (only for this section) and because of readability adopt ``gradient writing''
%
%Subgradients:
%\(\mathcal{G}_{upp,\lambda}, \mathcal{G}_{upp,w},\mathcal{G}_{upp,b}\) -> subgradients of outer objective \\
%\(g_w, g_b\) -> subgradient of w, b
%
%\[ final subgradient = \left(\mathcal{G}_{upp,w}(w,b,\lambda)\right)^{\top}g_w+\left(\mathcal{G}_{upp,b}(w,b,\lambda)\right)^{\top}g_b+\mathcal{G}_{upp,\lambda}(w,b,\lambda) 
%\label{subgr_upp}\]
%
%subgradients \(\mathcal{G}_{upp,...}\) easy to find (assumption that locally Lipschitz) -> in this application differentiable
%
%difficulty: find \(g_w, g_b\)
%important: optimality condition must be a linear system in \(w,b\) -> this is the case in this application
%\[ H(\lambda)\cdot (w,b)^{\top} = h(\lambda) \]
%
%find subgradients of each element (from differentiation rules follows)
%
%\[ \partial_{\lambda} H\cdot (w,b)^{\top} + H \cdot(\partial_{\lambda} w, \partial_{\lambda} b)^{\top} = \partial_{\lambda} h  \]
%
%solve this for \((w,b)\):
%\[ (\partial_{\lambda} w, \partial_{\lambda}b)^{\top} = H^{-1}\left(\partial_{\lambda}h-\partial_{\lambda} H \cdot(w,b)^{\top}\right) \]
%
%matrix \(H\) has to be inverted -> in the feature space so scalable with size of data set -> still can be very costly \cite{Moore2011}
%
%Applied to the two bilevel classification problems derived above, the subgradients have the following form:
%
%derivative of upper level objective:
%Notation: \(\delta_i := 1-y_i(w^{\top}x^i-b)\)
%
%\begin{align}
	%\partial_{w}\mathcal{L}_{upp}&= \frac{1}{T}\sum_{t=1}^T\frac{1}{\mathcal{N}_t}\sum_{i \in \mathcal{N}_t}{\left\{\begin{array}{cl} -y_ix^i & \text{if } \delta_i >0 \\ 0 & \text{if } \delta_i \leq 0 \end{array} \right.} \\
	%\partial_{b}\mathcal{L}_{upp}&= \frac{1}{T}\sum_{t=1}^T\frac{1}{\mathcal{N}_t}\sum_{i \in \mathcal{N}_t}{\left\{\begin{array}{cl} y_i & \text{if } \delta_i >0 \\ 0 & \text{if } \delta_i \leq 0 \end{array} \right.}
	%\end{align}
	%
	%here at the kink subgradient 0 is taken
%
%for hingequad: -> here subgradient \\
%optimality condition:
%\begin{align}
	%0 = \partial_{w}\mathcal{L}_{low} &= \lambda w+2\sum_{i \in \bar{\mathcal{N}_t}}{\left\{\begin{array}{cl} (1-y_i(w^{\top}x^i-b))(-y_ix^i) & \text{if } \delta_i >0 \\ 0 & \text{if } \delta_i \leq 0 \end{array} \right.} \\
	%0 = \partial_b\mathcal{L}_{low} &= 2\sum_{i \in \bar{\mathcal{N}_t}}{\left\{\begin{array}{cl} (1-y_i(w^{\top}x^i-b))(y_i) & \text{if } \delta_i >0 \\ 0 & \text{if } \delta_i \leq 0 \end{array} \right.}
	%\end{align}
	%
%subgradient??? is this smooth? with respect to \(\lambda\)
%\begin{align}
	%0 &= w+\lambda\partial_{\lambda}w+2\sum_{i \in \bar{\mathcal{N}_t}}{\left\{\begin{array}{cl} (-y_i(\partial_{\lambda}w^{\top}x^i-\partial_{\lambda}b))(-y_ix^i) & \text{if } \delta_i >0 \\ 0 & \text{if } \delta_i \leq 0 \end{array} \right.} \\
	%0 &= 2\sum_{i \in \bar{\mathcal{N}_t}}{\left\{\begin{array}{cl} (-y_i(\partial_{\lambda}w^{\top}x^i-\partial_{\lambda}b))(y_i) & \text{if } \delta_i >0 \\ 0 & \text{if } \delta_i \leq 0 \end{array} \right.}
%\end{align}
%
%From this the needed subgradients can be calculated via:
%
%\begin{equation}
	%2\cdot\begin{pmatrix} \frac{\lambda}{2}+\sum_{i \in \bar{\mathcal{N}_t}}{y_i^2x^i(x^i)^{\top}} & \sum_{i \in \bar{\mathcal{N}_t}}	{-y_i^2x^i} \\ \sum_{i \in \bar{\mathcal{N}_t}}{-y_i^2(x^i)^{\top}} & \sum_{i \in \bar{\mathcal{N}_t}}{y_i^2}\end{pmatrix}
	%\cdot \begin{pmatrix} \partial_{\lambda}w \\ \partial_{\lambda}b\end{pmatrix}
	%= \begin{pmatrix}-w \\ 0\end{pmatrix}
%\label{subgr_wb}
%\end{equation}
%
%for hinge not quad:
%
%not as much information in the subgradient/derivative
%
%similar calculation leads to 
%
%\begin{align}
	%\partial_{\lambda}w &= -\frac{w}{\lambda} \\
	%\partial_{\lambda}b &= 0
%\end{align}
%
%\textcolor{red}{does not work with just Hingeloss because set valued optimality condition --> have to find ``corresponding'' equation to the chosen subgradient --> do not know how}
%
%\subsubsection{Multi Group Model}
%
%Idea: different samples within the group have different have different quality --> put the samples with similar quality within one group --> give it its own \(\lambda_g\) such that the groups are weighted depending on their quality.
%
%two goals: better modleing and implicit information about the groups provided by the parameter \(\lambda_g\) -> small \(\lambda\) good quality, large \(\lambda\) bad quality???
%
%Examle: different people do same experiment; measure same data...
%
%\textbf{Model (Bilevel Problem)}
%
%
%for simplicity: all groups of same size; in all folds same number of elements of each group
%
%!! not possible to work with \(\lambda\) here, have to work with \(C\)-Formulation
%
%
%
%matrices for MATLAB calculations:
%
%\begin{equation*}
%\begin{split}
	%& \frac{1}{2} \langle x,Hx \rangle + h \\
	%& Ax \leq b
%\end{split}
%\end{equation*}
%
%\begin{equation}
	%H = \begin{pmatrix}
		%\mathbb{I}_{n\times n} \\
		%& 0 \\
		%& & 2 C \\
	%\end{pmatrix}
	%\in \R^{feat+1+J\max\{T-1,1\}G\times feat+1+J\max\{T-1,1\}G}
%\end{equation}
%
%\[ h = 0, \qquad A = \begin{pmatrix} -YX^{\top} & Y & -\mathbb{I}_{J\max\{T-1,1\}G \times J\max\{T-1,1\}G} \\ \end{pmatrix},  \qquad b = -\mathtt{ones}(J\max\{T-1,1\}G,1) \] 
%
%with \(C = [\underbrace{c_1,...,c_1}_{J\max\{T-1,1\} \text{ times}},c_2,...,c_2,...,c_G,...,c_G]^{\top}\).
%
%\textbf{Derivatives}
%
%overall gradient:
	%\[ \frac{\textup{d}\mathcal{L}_{upp}}{\textup{d}\lambda} = {\underbrace{\frac{\partial \mathcal{L}_{upp}}{\partial (w,b)}}_{\in \R^{n+1}}} ^{\top} \underbrace{\frac{\partial (w,b)}{\partial \lambda}}_{\in \R^{n+1 \times G}} \in \R^G\]
%
%
%gradient outer level objective: 
	%\[ \frac{\partial \mathcal{L}_{upp}}{\partial w} = \frac{1}{T}\sum_{t=1}^T\frac{1}{|\mathcal{N}_t|}\sum_{i \in \mathcal{N}_t} \delta_i \left( -y_i x^i\right) \in \R^n\]
	%
	%\[ \frac{\partial \mathcal{L}_{upp}}{\partial b} = \frac{1}{T}\sum_{t=1}^T\frac{1}{|\mathcal{N}_t|}\sum_{i \in \mathcal{N}_t} \delta_i y_i \in \R\]
	%
	%\[ \delta_i = \left\{ \begin{array}{cl} 1 & \text{if } 1-y_i\left(\Langle w,x^i\Rangle-b\right) > 0 \\
		%0 & \text{else}\end{array} \right.\]
%
%
%in MATLAB: 
	%\[ \frac{\partial \mathcal{L}_{upp}}{\partial w} = \frac{1}{T}\texttt{sum}(-\texttt{bsxfun}(\texttt{@times},X,\texttt{delta}.*Y) ,2) \in \R^n\]
	%
	%\[ \frac{\partial \mathcal{L}_{upp}}{\partial b} = \frac{1}{T}\texttt{sum}(\texttt{delta}.*Y ,1) \in \R\]
	%
	%
%gradient lower level objective:\\
%first optimality conditions \(0 = \frac{\partial \mathcal{L}_{low}}{\partial w}, 0 = \frac{\partial \mathcal{L}_{low}}{\partial b}\):
	%\[ 0 = {\sum_{g = 1}^G(\lambda_g}w) + 2\sum_{i \in \bar{\mathcal{N}}_t}\delta_i \left\{1-y_i\left(\Langle w,x^i\Rangle -b\right) \right\}(-y_ix^i) \in \R^n \]
		%
	%\[0 = 2\sum_{i \in \bar{\mathcal{N}}_t}\delta_i \left\{1-y_i\left(\Langle w,x^i\Rangle -b\right) \right\}(y_i) \in \R \]
	%
	%derivatives with respect to \(\lambda_g, g = 1,...,G\), then \(\in \R^{n+1 \times G}\)
	%
	%write one column of the matrix \(\in \R^{n+1}\) \(\to\) \(G\) such columns:
	%
	%\[ 0 = w + \lambda_g\frac{\partial w}{\partial \lambda_g} + 2 \sum_{i \in  \bar{\mathcal{N}}_t} \delta_i \left(y_i^2x^i(x^i)^{\top}\frac{\partial w}{\partial \lambda_g} - y_i^2x^i \frac{\partial b}{\partial \lambda_g}\right) \in \R^n \]
	%
	%\[ 0 = 2\sum_{i \in  \bar{\mathcal{N}}_t} \delta_i \left(-y_i^2(x^i)^{\top} \frac{\partial w}{\partial \lambda_g} + y_i^2 \frac{\partial b}{\partial \lambda_g}\right) \in \R\] 
%
%
	%rewrite to calculate \([\partial w / \partial \lambda, \partial b / \partial \lambda]^{\top} \in \R^{n+1 \times G}\) \(\to\) have to calculate every column of this matrix on its own \\
	%solve \(G\) times this system of equations
	%
	%\[ 2\begin{pmatrix} \frac{\lambda_g}{2}\mathbb{I}+\sum_{i \in  \bar{\mathcal{N}}_t}{\delta_i(y_i^2x^i(x^i)^{\top})} &  \sum_{i \in  \bar{\mathcal{N}}_t} \delta_i (- y_i^2x^i )	\\
	%\sum_{i \in  \bar{\mathcal{N}}_t} \delta_i (-y_i^2(x^i)^{\top}) & \sum_{i \in  \bar{\mathcal{N}}_t} \delta_i (y_i^2 )
	%\end{pmatrix} 
	%\begin{pmatrix}	\frac{\partial w}{\partial \lambda_g} \\ \frac{\partial b}{\partial \lambda_g}
	%\end{pmatrix} 
	%= \begin{pmatrix} -w \\ 0	\end{pmatrix} \]
%










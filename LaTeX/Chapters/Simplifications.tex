\section{Variations of The Bundle Method}

After their discovery in 1975 bundle methods became very successful. Only a few years after that they were generalized to be used also with nonconvex objective functions. Early works, that contain fundamental ideas still used for these algorithms are \cite{Mifflin1982} and \cite{Kiwiel1985}. It then took over 25 years that bundle methods were again generalized to the use of inexact information. The first works on this subject being \cite{Hintermueller2001,Kiwiel2006} and \cite{Solodov2003}.

This section of the thesis shortly presents the key ideas of those two kinds of generalizations and different types of bundle methods that realize them.
This is first done for the case of convex objective functions with inexact function value and/or subgradient information and then for nonconvex objective functions. 


\subsection{Convex Bundle Methods with Inexact Information}

We focus here on convex bundle methods with inexact information. The reason for this is that there is a fundamental difference in treating inexactness between methods that assume convex and those that assume nonconvex objective functions.
When dealing with nonconvex objective functions inexactness is treated as some additional nonconvexity. This is not possible when assuming convex objective functions and the convexity property is to be exploited for better convergence results.
A throughout study on this subject including a synthetic convergence theory is done in \cite{Oliveira2014}. Here the most important aspects \textcolor{red}{in view of the following chapters are reviewed.}

\subsubsection{Degrees of Inexactness}

2 a) What information is inexact (only subgradients/both...) --> what do you gain from this?


2 b) What kind of assumptions are on the inexactness? (asymptotic, only over- /underestimation?)exactness only for serious steps,accuracy controllable or not

\textcolor{red}{Different ``degrees'' of inexactness: inexact subgradients; also function values (only subgradients easier???); asymptotically ecact; , not at null steps;  --> throughout study in in depth paper.}

1. How is generally dealt with inexact information in the algorithms \\

\textcolor{red}{possible simplifications of the algorithm} \\
Convergence for inexact convex functions:
\begin{itemize}
	\item states in paper \cite{Hare2016} (p. 14) that for convex functions error of \(\bar{\sigma}\) instead of \(2\bar{\sigma}\) possible (and for lower models; see depth paper?)
\end{itemize}
%\begin{itemize}
	%\item recognized: fundamentally different? approach for convex and nonconvex functions (at least in algorithm) \\
	%convex: ``deal'' with inexactness; extra steps... \\
	%nonconvex: generally no difference in algorithm (but for example line search not possible --> only no change, if algorithm was suitable before)
	%\item nonconvex algorithms: inexactness is seen as some kind of nonconvexity --> for function values clear, for subgradients???
%\end{itemize}

%\textcolor{blue}{seems to be the same:
%\begin{align}
	%& \|g_a-g\| \leq \theta \\
	%\Leftrightarrow \quad & g_a \in \partial f + B_\theta(0) \\
	%\Leftrightarrow \quad & g_a \in \partial_{\varepsilon}f, \quad \theta \leq \varepsilon^2
%\end{align}
%Last implication only for convex functions because \(\varepsilon\)-subdifferential otherwise not defined.
%See also papers from ``Chinese-search''} \\

\subsection{Nonconvex Bundle Methods with Exact Information}

There are different approaches for handling nonconvexity of the objective function in bundle methods.
As the nonnegativity property of the linearization errors \(e_j^k\) is crucial for the convergence proof of convex bundle methods an early idea was forcing the errors to be so by different downshifting strategies. A very common one is using the \emph{subgradient locality measure} \cite{Kiwiel1986, Mifflin1982}. Here the linearization error is essentially replaced by the nonnegative number

\begin{equation}
	\tilde{e}_j^k := \max_{j \in J_k} \{|e_j^k|,\gamma \|\hat{x}^k-x^j\|^2\}
\label{subgr_loc_measure}
\end{equation}

or a variation of this expression.

The expression gradient locality measure comes from the dual point of view, where the aggregate linearization error provides a measure for the 'distance' of the calculated \(\varepsilon\)-subgradient to the objective function.

Methods that use downshifting for building the model function are often endowed with a line search to provide sufficient decrease of the objective function. For the linesearch to terminate finitely, usually semismoothness of the objective function is needed.

Instead of using line search it is also possible to do \emph{proximity control}. This means that the step size parameter \(t_k\) is managed in a smart way to ensure the right amount of decrease in the objective function. This method is very helpful in the case of nonconvex objective functions with inexact information as it is predominantly considered in this thesis.

As inexactness can be seen as a kind of slight nonconvexity one could be tempted to think that nonconvex bundle methods are destined to be extended to the inexact case. Indeed, the two existing algorithms \cite{Hare2016,Noll2013} that deal with both nonconvexity and inexactness are both extensions of a nonsmooth bundle method.
This is however seldom possible for algorithms that employ a line search because for functions with inexact information convergence of this subroutine cannot be proven.

To this end proximity control seems to be a very promising strategy. It is used in many different variations in \cite{Apkarian2008, Lewis2015, Noll2005, Noll2010, Noll2012, Schramm1992}

In the beginning bundle methods were mostly explored from the  dual point of view. Newer concepts focus also on the primal version of the method. This invokes for example having different model functions for the subproblem.

In \cite{Fuduli2004, Fuduli2004a} the difference function 

\begin{equation}
	h(d):= f(x^j +d) -f(x^j) \quad j \in J_k
\label{diff_fun}
\end{equation}

is approximated to find a descent direction of \(f\).
The negative linearization errors are addressed by having two different bundles. One containing the indices with nonnegative linearization errors and one containing the other ones. From these two bundles two cutting plane approximations can be constructed which provide the bases for the calculation of new iterates.

In \cite{Noll2012} Noll et al. follow an approach of approximating a local model of the objective function. The model can be seen as a nonsmooth generalization of the Taylor expansion and looks the following:

\begin{equation}
	\Phi(y,x) = \phi(y,x)+\frac{1}{2}(y-x)^{\top}Q(x)(y-x)
\label{quad_mod}
\end{equation}

The so called \emph{first order model} \(\phi(.,x)\) is convex but possibly nonsmooth and can be approximated by cutting planes. The \emph{second order part} is a quadratic but not necessarily convex. The algorithm then proceeds a lot in the lines of a general bundle algorithm.
Instead of a line search is uses proximity control to ensure convergence.

Generally for all of this methods convergence to a stationary point is established under the assumptions of a locally Lipschitz objective function and bounded level sets \(\{x \in \R^n | f(x) \leq f(\hat{x}^1)\}\).
If the method uses a line search additionally semismoothness of the objective function is needed.

In \cite{Noll2013} the second order approach of \cite{Noll2012} is extended to functions with inexact information.
As far a we know this is the only other bundle method that can deal with nonconvexity and inexactness in both the function value and subgradient. It inspires the variable metric variation of the method used by Hare et al. in \cite{Hare2016} that is presented in section \ref{variable_metric} of this thesis.

To conclude this section we can say: At the moment there exist two fundamentally different approaches to tackle inexactness in various bundle methods depending on if the method is developed 	for convex or nonconvex objective functions.
In the nonconvex case inexactness is only considered in the paper by Hare, Sagastiz{\`{a}}bal and Sodolov \cite{Hare2016} presented above and Noll \cite{Noll2013}. In these cases the inexactness can be seen as an ``additional nonconvexity''. In practice this means that the algorithm can be taken from the nonconvex case with no or only minor changes.
In case of convex objective functions changes in the algorithm are more involved. The reason for this is that generally stronger convergence results are possible with inexactness in the convex case than in the nonconvex case. This means however, that the inexactness cannot be incorporated as easily into the algorithm.

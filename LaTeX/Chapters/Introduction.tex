\section{Introduction}

\textcolor{red}{Often in practical optimization applications, the derivative bases framework of classical optimization cannot be used, because the objective function is not necessarily differentiable. \(\rightarrow\) examples.} \\
To tackle this problem the framework of nondifferentiable (or nonsmooth) analysis was developed. \\
Additionally the problem of inexact information. 
The most promising algorithms \textcolor{red}{\(\rightarrow\) citation}  in this field are bundle algorithms. \\
\textcolor{red}{from PhD-thesis}
\begin{itemize}
	\item two kinds of algorithms for nonsmooth \\
	subgradient \\
	bundle methods \\
	\item short description of history (of both???)
	\item 
\end{itemize}

Write about developement for convex in beginning.
In this thesis different versions of bundle methods that allow for inexact information for both function values and subgradients are examined more closely. \\
First a proximal bundle method \textcolor{red}{\(Difference between different regularizations explained before\)}...
large-scale optimization: a metric bundle method instead of a proximal bundle method -> limited memory approach \\
Organization as follows: introduction of the most important definitions and results of nonsmooth analysis. Then the introduction of a very basic bundle algorithm which is then generalized for nonconvex functions with nonsmooth optimization. \\
Throughout study of this algorithm including comparison to other approaches to tackle inexact information. \\
Introduction of variable metric (bundle) algorithm to tackle large-scale applications. ``discussion'' how far this is compatible with inexactness. \\
Numerical testing \\ 
discussion \\

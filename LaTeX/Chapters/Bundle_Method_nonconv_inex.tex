\section{Proximal bundle method for nonconvex functions with inexact information} \label{sec_nonconv_inex}

%\textcolor{blue}{introduction}

This section focuses on the proximal bundle method presented by Hare et al. in \cite{Hare2016}.
The idea is to extend the basic bundle algorithm for nonconvex functions with both inexact function and subgradient information.
The key idea of the algorithm is the one already developed by Hare and Sagastizábal in \cite{Hare2010}: When dealing with nonconvex functions a very critical difference to the convex case is that the linearization errors are not necessarily nonnegative any more. To tackle this problem the errors are manipulated to enforce nonnegativity. In this case this is done my modeling not the objective function directly but a convexified version of it.

\subsection{Derivation of the Method}
%\textcolor{blue}{``assumptions and notations''}

%\textcolor{red}{introduce exact optimization problem that is used in this section and its properties if not already introduce in ``Preliminaries''.}

Throughout this section we consider the optimization problem

\begin{equation}
	\min_{x} f(x) \quad \text{s.t.} \quad x \in X.
\label{opt_prob_nonconv_inex}
\end{equation}

The objective function \(f:\R^n \to \R\) is locally Lipschitz  and (subdifferentially) regular. \(X \subseteq \R^n\) is assumed to be a convex compact set. 

%\begin{definition} \cite{Rockafellar2009}
	%A function \(f:\R^n \to \bar{\R} = [-\infty, + \infty]\) is called \emph{proper} if \(f(x) < \infty\) for at least one \(x\in \R^n\) and \(f(x) > \infty ~ \forall x \in \R^n\).
%\end{definition}

\begin{definition} \cite[Theorem 7.25]{Rockafellar2009}
	\(f: \R^n \to \bar{\R}\) is called \emph{subdifferentially regular} at \(\bar{x}\) if \(f(\bar{x})\) is finite and the epigraph
	\[epi(f) := \{(x, \alpha) \in \R^n\times \R | \alpha \geq f(x)\}\]
	is Clarke regular at \(\bar{x},f(\bar{x})\).
\end{definition}

\subsubsection{Inexactness}

Both the function value as well as one element of the subdifferential can be provided in an inexact form.

For the function value inexactness is defined straight forwardly: If 
\begin{equation*}
	\|f_x - f(x)\| \leq \sigma_x
\label{fun_inex}
\end{equation*}

then \(f\) approximates the value \(f(x)\) within \(\sigma_x\). This is a little bit different from the definition in (\ref{conv_inexactness_1}). In the convex case it follows from (\ref{sig_p_thet_subgr}) that \( \bar{\sigma} \geq \sigma_x \geq -\theta_x \geq - \bar{\theta}\) and therefore \(f_x \in [f(x)-\bar{\theta},f(x)+\bar{\sigma}]\).

As the 'normal' \(\varepsilon\)-subdifferential is not defined for nonconvex functions we adopt the notation used in \cite{Noll2013} and interpret inexactness in the following way: \(g \in \R^n\) approximates a subgradient  of \( \partial f(x)\) within \(\theta \geq 0\) if
\begin{equation*}
	g \in \partial f(x) + B_{\theta}(0) := \partial_{[\theta]}f(x)
\label{subgr_inex}
\end{equation*}

where \(\partial f(x)\) is the Clarke subdifferential %\textcolor{red}{defined in Preliminaries section}
of \(f\).

The given definition of the inexactness can be motivated by the relation 
	\[ g \in \partial_{[\theta]}f(x)\Leftrightarrow g \in \partial(f+\theta\|\cdot-x\|)(x) \]
noticed in \cite{Treiman1986}. It means that the approximation of the subgradient of \(f(x)\) is an exact subgradient of a small perturbation of \(f\) at \(x\).
\(\partial_{[\varepsilon]}f(x)\) is also known as the Fréchet \(\varepsilon\)-subdifferential of \(f(x)\).

%\begin{definition}\cite{Jofre1998}
	%Let \(f:\R^n \to \R\), \(\varepsilon\) > 0. The \emph{Fréchet \(\varepsilon\)-subdifferential} of \(f\) at \(x\) is defined by 
	%\[ \partial_{[\varepsilon]}f(x) := \left\{g \in \R^n | \liminf_{\|h\| \to 0} \frac{f(x+h)-f(x)-\langle g, h\rangle}{\|h\|} \geq -\varepsilon \right\}. \]
%\end{definition}


\begin{remark}
For convex objective functions this approximate subdifferential does \emph{not} equal the usual convex \(\varepsilon\)-subdifferential. The two can however be related via

\[ \partial_{\theta}f(x) \subset \partial_{[\theta']}f(x) \]
 
for a suitable \(\theta'\). Generally an explicit relation between \(\theta\) and \(\theta'\) is hard to find \cite{Noll2013}.
\end{remark}

Like in the paper it is assumed that the errors are bounded although the bound does not have to be known:

\begin{equation*}
	|\sigma_j| \leq \bar{\sigma} > 0 \quad \text{and} \quad 0 \leq \theta_j \leq \bar{\theta} \quad \forall j \in J^k.
\label{err_bound}
\end{equation*}

%In the context of inexact information it is important to make a distinction between the (unknown) exact function value and its approximation. Throughout this section we therefore write \(f(x^j)\) for the exact function value  whereas the approximation will be written as \(f_j\)  or \(\hat{f}_k\) for the approximation at the current stability center.
For ease of notation we write from now on \(f_j\) instead of \(f_{x^j}\) for the approximation of the function value at the \(j\)'th iterate in the bundle \(J\). The approximation at the \(k\)'th stability center reads \(\hat{f}_k\).


%\textcolor{red}{remark to subgradient notation\\
%sensible in view of optimality condition \(\to\)
%\[  \] 
%this means that perturbation of \(f\) is critical at \(x\) \\
%for convex functions the two subdifferentials can be related
%\[ \partial_{\theta}f(x) \subset \partial_{[\theta']}f(x) \]
%for convex \(f\) set  \(\partial_{[\theta]} f(x)\) coincides with Fréchet \(\varepsilon\)-subdifferential \\
%subdifferential in Hare-Paper:
%\[ \partial f(\bar{x}) = \left\{g \in \R^n | \lim_{x \to \bar{x}} \inf_{x \neq \bar{x}} \frac{f(x)-f(\bar{x})-\langle g, x - \bar{x}\rangle}{\|x - \bar{x}\|} \geq 0 \right\} \]
%Fréchet-Subdifferential in \cite{Kruger2003}
%\[ \partial f(\bar{x}) = \left\{g \in \R^n | \liminf_{x \to \bar{x}} \frac{f(x)-f(\bar{x})-\langle g, x - \bar{x}\rangle}{\|x - \bar{x}\|} \geq 0 \right\} \]
%said to be the same as \emph{regular subdifferential} in \cite{Rockafellar2009}
%\[ \hat{\partial}f(\bar{x}) = \left\{ v \in \R^n | \liminf_{\substack{x \to \bar{x} \\x \neq \bar{x}}} \frac{f(x)-f(\bar{x})- \langle v, x - \bar{x}\rangle}{\|x-\bar{x}\|} \geq 0\right\} \]
%\(\Rightarrow\) all the same \\
%\cite{Jofre1998} defines Fréchet \(\varepsilon\)-subdifferential for \emph{lower semicontinuous} functions as
%\[ \partial^{F}_{\varepsilon}f(x) = \left\{g \in \R^n | \liminf_{\|h\| \to 0} \frac{f(x+h)-f(x)-\langle g,h \rangle}{\|h\|} \geq -\varepsilon \right\} \]
%also says \(f\) convex \(to\) limiting Fréchet \(\varepsilon\)-subdifferential is exactly \(\varepsilon\)-enlargement of Frenchel subdifferential.\\
%Treiman \cite{Treiman1986}: \(g \in \partial^F_{\varepsilon}f(x) \Leftrightarrow g \in \partial^F(f+\varepsilon\|\cdot-x\|)(x)\)\\
%\(f\) convex \(\to\)
%\[ \partial^{F}_{\varepsilon}f(x) = \left\{g \in \R^n | \frac{f(x+h)-f(x)-\langle g,h \rangle}{\|h\|} \geq -\varepsilon, \forall h \in \R^n\right\}  \]
%``normal'' \(\varepsilon\)-subdifferential (VL Ulbrich, \cite{Hiriart-Urruty1993})
%\[ \partial_{\varepsilon}f(x) = \left\{g \in \R^n | f(y) -f(x) -\langle g, y-x\rangle \geq - \varepsilon, \forall y \in \R^n \right\} \]
%in Rockafellar: \(\bar{\partial}f(x)\) is generalization of Clarke subdifferential.\\
%in case of Lipschitz contiuity: convex hull of limiting proximal subgradients\\
%\[\bar{\partial} f(\bar{x})= \left\{v| (v,-1) \in \bar{N}_{\text{epi }f}(\bar{x},f(\bar{x}))\right\}\]
%\(f\) subdifferentially regular \(\Rightarrow\) \(\bar{\partial}f(\bar{x}) = \partial f(\bar{x})\) \\
%8.30: \(f\) subdifferentially regular: \(\Rightarrow\) \(\partial f(\bar{x}) = \left\{v|\langle v,w \rangle \leq \text{d}f(\bar{x})(w),  \forall w\right\}\)\(\to\) 8.4 same for \(\hat{\partial}f(x)\)\\
%8.9\\
%\(\text{d}f(\bar{x})(\bar{w}) = \liminf_{\substack{\tau \searrow 0 \\ w \to \bar{w}}}\frac{f(\bar{x}+\tau w)-f(\bar{x})}{\tau}\)\\
%8.11: subdifferentially regular functions \(\partial f(x) = \hat{\partial}f(x)\) \\
%\(\partial f(x) \) is a general subgradient (8.3)}

%\textcolor{red}{Closed convex sets are Clarke regular, so in particular the epigraph of \textcolor{red}{lower \(\mathcal{C}^2\)-functions?}.}

%\textcolor{red}{Definition semismooth for later:} \\
%\begin{definition} % as in \cite{Mifflin1977}
	%A function \(f: \R^n \to \R\) is called \emph{semismooth} ar \(x\in \R^n\) if \(f\) is Lipschitz near \(x\) and for each \(d \in \R^n\) and for any sequences \(\{t_k\} \subseteq \R_{+}, \{\theta^k\} \subseteq \R^n\) and \(\{g^k\} \subseteq \R^n\) such that 
	%\[ \{t_k\} \downarrow 0, \quad \{\theta^k/t_k\} \to 0 \in \R^n \quad \text{and} \quad g^k \in \partial f (x+t_kd+\theta^k), \]
	%the sequence \(\{\langle g^k, d \rangle\}\) has exactly one accumulation point.
%\end{definition}

%\begin{definition} % as in \cite{Haarala2004a}
%A point \(x \in \R^n\) that satisfies \(0 \in \partial f(x)\) is called a \emph{stationary point} of \(f\).
%\end{definition}

%\textcolor{blue}{explanation}

\subsubsection{Nonconvexity}

A main issue both nonconvexity and inexactness entail is that the linearization errors \(e_j^k\) are not necessarily nonnegative any more.
So based on the results in \cite{Hare2009} not the objective function but a convexified version of it is modeled as the objective function of the subproblem.
%\textcolor{red}{explain locally convexified more precisely? Is it because no global convexification? different than in [18]??}\\

%When looking at the subproblem formulated as in (\ref{sub_prob_long}) one can see that the new iterate \(x^{k+1}\) is in fact a \emph{proximal point} of the subproblem.\\
%The \emph{proximal point mapping} or \emph{prox-operator} is defined as
%\begin{equation}
	%prox_{t,f}(x) = \argmin_{y}\left\{\check{f}(y) + \frac{1}{2t}\|x-y\|^2\right\}, \quad t > 0
%%\label{prox_op}
%\end{equation}

%For \(\check{f}(x) := m_(x)+\mathbb{I}_X(x)\) and \(\mu:=\frac{1}{t_k}\) this is just subproblem (\ref{sub_prob_long}) with the constraint \(x\in X\) incorporated in the objective function. Because of this special form of the subproblems primal bundle methods are also called proximal bundle methods.\\

As already pointed out in \ref{subsec_prox_op} the bundle subproblem can be formulated by means of the prox-operator (\ref{prox_op}).

%\textcolor{red}{explain in much more detail when read about calculation of proximal points for nonconvex functions. At the moment just main ideas.}

The key idea is to use the relation
\begin{equation*}
	prox_{T = \frac{1}{\eta}+t, f}(x) = prox_{t,f+\eta/2|\cdot - x|^2}(x).
\label{prox_relation}
\end{equation*}

This means, that the proximal point of the function \(f\) for parameter \(T=\frac{1}{\eta}+t\) is the same as the one of the convexified function 

\begin{equation}
	\tilde{f}(y) = f(y) + \frac{\eta}{2}|y-x|^2
\label{conv_obj}
\end{equation}

with respect to the parameter \(t\) \cite{Hare2010}. \(\eta\) is therefore called the \emph{convexification parameter} and \(t\) the \emph{prox-parameter}.\\

%\textcolor{red}{say why/how... this is related to current stability center}
%\textcolor{red}{Because new function to be approximated, subgradients ``new'':}
The main difference of the method in \cite{Hare2016} to the basic bundle method is that the function that is modeled by the cutting plane model s no longer the original objective function \(f\) but the convexified version \(\tilde{f}\). This results in the following changes:

In addition to downshifting the linear functions forming the model  they have a tilted slope.
This is because instead of subgradients of the original objective \(f\) subgradients of the function \(\tilde{f}\) are taken. We call them \emph{augmented subgradients}.
At the iterate \(x^j\) it is given by

\begin{align*}
	s^k_j &= g^j + \eta_k \left(x^j-\hat{x}^k\right).
	\label{aug_subgr}
\end{align*}

%Additionally they are shifted downwards to keep the linearization error nonnegative
Downshifting is done in a way that keeps the linearization error nonnegative.
The \emph{augmented linearization error} is therefore defined as 

\begin{equation*}
	0 \leq c^k_j := e^k_j + b_j^k, \quad \text{with} \quad \left\{ \begin{array}{l} e_j^k := \hat{f}_k - f_j - \Langle g^j, \hat{x}^k-x^j\Rangle	 \vspace{1ex} \\
	b_j^k := \frac{\eta_k}{2}\|x^j-\hat{x}^k\|^2 \end{array}\right.
\label{aug_lin_err}
\end{equation*}

and 

\begin{equation*}
	\eta_k \geq \max\left\{\max_{j \in J_k, x^j \neq \hat{x}^k}{ \frac{-2e_j^k}{\|x^j-\hat{x}^k\|^2}}, 0 \right\} + \gamma. 
\label{eta}
\end{equation*}

The parameter \(\gamma \geq 0\) is a safeguarding parameter to keep the calculations numerically stable.


The new model function can therefore be written as
\begin{equation*}
  M_k(\hat{x}^k +d) := \hat{f}_k + \max_{j \in J_k} \left\{\Langle s^k_j,d\Rangle -c^k_j \right\}.
\label{aug_model}
\end{equation*}

\subsubsection{Aggregate Objects}

The definition of the \emph{augmented aggregate subgradient} \(S^k\),  \emph{error} \(C_k\) and \emph{linearization} \(A_k\) follows straightforwardly:

\begin{align}
	&S^k := \sum_{j \in J_k} \alpha_j^k s_j^k \label{aug_agg_subgr}, \\
	&C_k := \sum_{j \in J_k}{\alpha_j^k c_j^k} \\%\label{aug_agg_err} \text{ and }
	& A_k(\hat{x}^k+d) := M_k(x^{k+1})+\left\langle S^k, d-d^k \right\rangle \label{aug_agg_lin}.
\end{align}

Just as the model decrease
\begin{equation}
	\delta^k := C_k + t_k \|S^k + \nu^k\|^2,
\label{mod_dec2}
\end{equation}

which contains the normal vector 
\begin{equation}
	\nu^k \in \partial\mathtt{i}_X(x^{k+1})
	\label{nu}
\end{equation}
of the constraint set \(X\).

By the same argumentation as for (\ref{agg_err}) the KKT conditions also reveal another useful characterization of the augmented aggregate linearization error:

\begin{equation}
	C_k = \hat{f}_k - M_k(x^{k+1})+\Langle S^k, d^k \Rangle
\label{aug_agg_err2}
\end{equation}

As the model function is convex even for nonconvex objective functions it is still minorized by the aggregate linearization. It holds 

\begin{equation}
	A_K(\hat{x}^k+d) \leq M_k(\hat{x}^k+d).
\label{A_leq_M}
\end{equation}

The update of \(t_k\) can be done in the same way described in (\ref{t_plus}) and (\ref{t_minus}) for the basic bundle method. Similarly  the methods to update the bundle index set \(J^k\) stay valid.
The update conditions (\ref{model_update_1}) and (\ref{model_update_2}) for the model are now written with respect to the augmented aggregate linearization and the approximate function value \(\hat{f}_{k+1}\).

\begin{align}
	&M_{k+1}(\hat{x}^k+d) \geq \hat{f}_{k+1}-c^{k+1}_{k+1}+\left\langle s^{k+1},d \right\rangle \label{Model_update_1}\\
	&M_{k+1}(\hat{x}^k+d) \geq A_k(\hat{x}^k+d).
	\label{Model_update_2}
\end{align}

A bundle algorithm that deals with nonconvexity and inexact function and subgradient information can now be stated.

%\textcolor{blue}{algorithm}


\begin{minipage}{\linewidth}
Algorithm \ref{sec_nonconv_inex}.1:
\vspace{1em}

\hrule  \vspace{0.4ex} \hrule
\vspace{1ex}
\textbf{Nonconvex Proximal Bundle Method with Inexact Information}
\vspace{1ex}
\hrule
\vspace{1ex}
Select parameters \( m \in (0,1), \gamma > 0 \) and a stopping tolerance \( \mathtt{tol} \geq 0\). \\
Choose a starting point \(x^1 \in \R^n\) and compute \(f_1\) and \(g^1\). Set the initial index set \(J_1:=\{1\}\) and the initial prox-center to \(\hat{x}^1 := x^1\), \(\hat{f}_1 = f_1\) and select \(t_1 > 0\).
\end{minipage}

For \(k = 1,2,3,  \dotsc \)   

\begin{enumerate}
	\item Calculate \[d^k = \arg \min_{d \in \R^n} \left\{ M_k(\hat{x}^k+d)+\mathbb{I}_X(\hat{x}^k+d)+\frac{1}{2t_k}\|d\|^2\right\}.\]
	\item Set
		\begin{align*} 
		  G^k &= \sum_{j \in J_k}{\alpha_j^k s_j^k}, \quad \nu^k \in \partial \mathtt{i}_{X}(x^{k+1}) \\
			C_k &= \sum_{j \in J_k}{\alpha_j^k c_j^k}, \\
	    \delta_k &=  C_k + t_k\|G^k + \nu^k\|^2.
		\end{align*}
		If \(\delta_k \leq \mathtt{tol} \rightarrow \) STOP.
	\item Set \( x^{k+1} = \hat{x}^k + d^k \).
	\item Compute \(f^{k+1}, g^{k+1}\). \\
	If 
	\[f^{k+1} \leq \hat{f}^k - m\delta_k \quad \rightarrow \text{ serious step} \]
	Set \(\hat{x}^{k+1} = x^{k+1}, \hat{f}^{k+1} = f^{k+1}\) and select \(t_{k+1} > 0\). \\
	Otherwise 
	\[\rightarrow \text{nullstep} \]
	Set \(\hat{x}^{k+1} = \hat{x}^k, \hat{f}^{k+1}=f^{k+1}\) and choose \(0 < t_{k+1} \leq t_k\). 	
	\item Select new bundle index set \(J_{k+1}\), calculate 
	\[ \eta_k \geq \max{\left\{\max_{j \in J_{k+1}, x^j \neq \hat{x}^{k+1}}{\frac{-2e_j^k}{|x^j - \hat{x}^{k+1}|^2}, 0}\right\}}+\gamma  \]
	and update the model \(M_k\).
\end{enumerate}
\vspace{1ex}
\hrule

\vspace{1.5em}

\subsection{On Different Convergence Results} \label{On_diff_conv_res}

In terms of usability of the described algorithm it is interesting to see if stronger convergence results are possible if additional assumptions are put on the objective function. This is investigated in the following section.

\subsubsection{The Constraint Set}

%The method above can handle nonconvex objective functions. It is not explicitly assumed, that the function taken has a finite minimum. Therefore
The constraint set \(X\) ensures the boundedness of the sequence \(\{\hat{x}^k\}\).
This is not necessary if the objective function is assumed to have bounded level sets \(\{x \in \R^n | f(x) \leq f(\hat{x}^1)\}\), an assumption commonly  used when optimizing nonconvex functions.
As the objective function is assumed to be continuous bounded level sets are compact. Additionally the descent test makes sure that \(f(\hat{x}^{k+1}) \leq f(\hat{x}^k)\) for all \(k\). The proof holds therefore in the same way as with the set \(X\).

\textcolor{red}{Another possibility is to bound the step sizes \(t_k\) also from above. Then the sequence \(\{\hat{x}^k\}\) also stay bounded and the proof still holds.
In \cite{Oliveira2014} another stopping criterion is psoposed that ensures convergence even for unbounded sequences \(\{\hat{x}^k\}\).
Is this also possible in my case or only for convex???}

\subsubsection{Exact Information and Vanishing Errors}

As the presented algorithm was originally designed for nonconvex objective functions where function values as well as subgradients are available in an exact manner, all convergence results stay the same with the error bounds \(\bar{\sigma} = \bar{\theta} = 0\).
As already indicated previously this is the case because inexactness can be seen as a kind of nonconvexity and no additional concepts had to be added to the method when generalizing it to the inexact setting.

If we additionally require the objective function to be lower-\(\mathcal{C}^2\) it can be proven that the sequence \(\{\eta_k\}\) is bounded \cite{Hare2010}.
This is not possible in the case of inexact information even for convex objective functions.

For asymptotically vanishing errors, meaning \(\lim_{k \to \infty} \sigma_k = 0 \) and \(\lim_{k \to \infty} \theta_k = 0 \) the convergence theory holds equally well with error bounds \(\bar{\sigma} = \bar{\theta} = 0\) in \cite[Lemma 5]{Hare2016}. Still it is difficult if not impossible to show that the sequence \(\{\eta_k\}\) is bounded without further assumptions.
\textcolor{red}{Under the assumption that \(f\) is lower-\(\mathcal{C}^2\) and some continuity bounds on the errors
\[ \frac{|\sigma_j-\hat{\sigma}_k|}{\|x^j-\hat{x}^k\|^2} \leq L_{\sigma}, \qquad \frac{\theta_j}{\|x^j-\hat{x}^k\|} \leq L_{\theta} \quad \forall k \text{ and } \forall j \in J_k\]
boundedness of the sequence \(\{\eta_k\}\) can be shown. The question remains however if those assumptions are possible to be assured in practice.} \\
\textcolor{red}{remark on \(\eta_k\)? how does it behave in my applications???}


%It can be shown however that under the condition that the error on the function value at the centers is Lipschitz continuous and the objective function is lower-\(\mathcal{C}^2\) the sequence \(\{\eta_k\}\) is  bounded.
%
%Let
%\begin{equation}
	%\frac{|\sigma_j-\hat{\sigma}_k|}{\|x^j-\hat{x}^k\|} \leq L_{\sigma}.
	%\label{Lip_error}
%\end{equation}
 %Then from (\ref{eta}) follows that 
%\begin{align}
	%\eta_k &= \max \left\{ \max_{\substack{j \in J^k \\ x^j \neq \hat{x}^k}} \frac{-2e^k_j}{\|x^j-\hat{x}^k\|^2},0\right\} +\gamma \\
	%&\leq \max \left\{ \max_{\substack{j \in J^k \\ x^j \neq \hat{x}^k}} \frac{-2\left(f(\hat{x}^k)+\hat{\sigma}_k-f(x^j)-\sigma_j-\langle \tilde{g}^j,\hat{x}^k-x^j\rangle-\langle p^j,\hat{x}^k-x^j \rangle \right)}{\|x^j-\hat{x}^k\|^2},0\right\} +\gamma \\
	%&\leq 2 (\frac{L_{\sigma} + 2L_{f}+\bar{\theta}}{\|x^{j^*}-\hat{x}^k\|})+\gamma
%\end{align}
%
%where \(j^* \in J^k\) yields the maximum of the expression for all \(j \in J^k\).
%Due to the local Lipschitz property of \(f\) and the fact that all iterates \(x^j \in X\). From \cite[Proposition 2.1.2]{Clarke1990} and the decomposition \(g^j = \tilde{g}^j+p^j\), \(\tilde{g}^j \in \partial_f(x^j)\) and \(p \in \mathbb{B}_{\theta_j}(0)\) follows \(\|g^j\| \leq L{f}+\theta_j \leq L_{f}+\bar{\theta}\).
%It is possible to satisfy assumption (\ref{Lip_error}) if it the accuracy with which each \(f\) is calculated is known. For example if \(f\) is the result of an optimization process where the exactness of the output can be controlled by the stopping tolerance.
%
%The above calculations for the boundedness of \(\{\eta_k\}\) still hold in case of exact function values but inexact subgradients by just setting \(\sigma_j=\bar{\sigma}=0\) for all \(j \in J\).

%\textcolor{red}{Problem: \(\{\eta_k\}\) seems to stay bounded even if objective is not lower-\(\mathcal{C}^2\) and therefore convexified function never gets convex \(\to\) no! have \(\|...\|^2\) then not bounded.\\
%for lower-\(\mathcal{C}^2\): \(\exists t_k\) such that \(f(x)+\frac{1}{2t_k}\|x-\hat{x}^k\|^2\) is convex; then ``exact'' part of the linearization error is always positive; \(\to\) then ``quadratic Lipschitz'' bound on \(\sigma\) needed and Lipschitz continuity on \(\theta\)\\
%makes maybe not so much sense then }

\subsubsection{Convex Objective Functions}

An obvious gain when working with convex objective functions is that the approximate stationarity condition of \cite[Lemma 5 (iii)]{Hare2016} is now an approximate optimality condition.
If one takes the error definitions (\ref{conv_inexactness_1}) and (\ref{conv_inexactness_2}) that are available in the convex case
and assumes \(X = \R^n\) statement (22) in \cite{Hare2016} therefore means that 

%0 is in the \(\bar{\sigma}+\bar{\theta}\)-subdifferential of \(f(\bar{x})\).

\[ 0 \in \partial_{\bar{\sigma}+\bar{\theta}}f(\bar{x}). \]

Thus \(\bar{x}\) is \((\bar{\sigma}+\bar{\theta})\)-optimal.

This follows from the definition of \(S^k\) in (\ref{aug_agg_subgr}) and local Lipschitz continuity of the \(\varepsilon\)-subdifferential \cite[Proposition 12.68]{Rockafellar2009}.

%...as laid down previously the definition of an approximate subgradient does not coincide with the usual \(\varepsilon\)-subdifferential for convex functions.
%\textcolor{red}{both definitions used for interpretation of last statement of Lemma 5.}
%It is therefore assumed that for convex objective functions the approximate subgradient \(g^j\) is taken from the \(\theta_j\)-subdifferential of \(f_j\)with \(\theta_j < \bar{\theta}\) for all \(j \in J\) as defined in (\ref{conv_inexactness_1}) and (\ref{conv_inexactness_2}).

%If \(f\) is convex and \(D = \R^n\) the last statement of \cite[Lemma 5]{Hare2016} states that if \(\{\hat{x}^k\} \to \bar{x}\) for \(K\ni k \to \infty\), then 

%\begin{equation}
	%0 \in \partial_{2\bar{\sigma}}f(\bar{x})+B_{\bar{\theta}}(0)
%\end{equation}
%
%if we stick to the definition of the Fréchet-\(\varepsilon\)-subgradients defined for the nonconvex case.
%
%If one takes the \(\bar{\theta}\)-subgradient definition it results in 
%
%\begin{equation}
	%0 \in \partial_{2\bar{\sigma}+\bar{\theta}}.
%\end{equation}
%
%\textcolor{red}{How can that be?????? Which optimality condition is right???}

%\textcolor{red}{Better convergence results? \(\bar{\sigma}\) instead of \(2\bar{\sigma}\)}

\textcolor{red}{
\begin{itemize}
	\item (iii) in Lemma 5 für conv eps-subdiff umschreiben
	\item beweis für \(\bar{\sigma}\)-optimalität
	\item
\end{itemize}}

\textcolor{red}{bounded \(t_k\) instead of D? better????}
%This means we consider now inexactness of the following type
%
%\begin{align}
	%f_j &= f(x^j)-\sigma_j, \sigma_j \leq \bar{\sigma} \\
	%g^j &\in \R^n \text{ such that } f(\cdot) \geq f^j + \langle g^j, \cdot - x^j \rangle - \theta_j,  ~\forall x^j \in \R^n, \theta_j \leq \bar{\theta}
%\end{align}

%\textcolor{red}{with the following changes in the proof of Lemma 5(iv?) ... changes ... can be achieved -> for both kinds of subgradients\\
%important in convex case: when is linearization error negative? -> then for example noise attenuation.\\
%think different concept needed for better error bounds}
%
\begin{itemize}
	\item convex objective function \\
	\(\to\) generally better convergence properties possible \\
	but more or less only on error bound???
	\(\to\) different concept of algorithm for convex inexact functions  to exploit convexity (contrary to nonconvex obj functions)
\end{itemize}


%In the exact case boundedness of the sequence \(\{\eta_k\}\) is proven for lower-\(\mathcal{C}^2\) functions in \cite{Hare2010}. This is not possible in the inexact case, even if the objective function \(f\) is convex.

%A further simplification of the method for exact information is not necessary as the method is already almost as simple as the basic bundle method for nonconvex exact functions. Additionally no new concepts needed to be introduced when doing the step from nonconvex exact problems, for which the algorithm was originally designed, to problems with inexact information.

%\textcolor{red}{\begin{remark}
	%We want to add here, that the simplicity of the algorithm is rather special for methods suitable for nonconvex problems. Often a linesearch algorithm has to be inserted in the nonconvex case, which is not needed here. 
%\end{remark}}

%\subsection{Convergence analysis}
%
%\subsubsection{Results for objectives with exact information}
%
%The main ideas of the algorithm are basicly the ones developed in \cite{Hare2010} for the redistributed proximal bundle method for exact nonconvex problems. \\
%Setting the error bounds \(\bar{\sigma}\) and \(\bar{\theta}\) to zero results therefore in the following convergence theorem. 
%
%\begin{theorem}
	%Let the sequence \(\{\eta_k\}\) be bounded, \(\liminf_{k \to \infty }\) and the cardinality of the set \(\{j \in J_k | \alpha_j^k > 0\}\) be uniformly bounded in \(k\). \\
	%Then every accumulation point of sequence of serious iterates \(\{\hat{x}^k\}\) is a stationary point of the problem.
%\end{theorem}
%
%\textcolor{red}{think last condition only interesting in inexact case.}
%
%In the exact case boundedness of the sequence \(\{\eta_k\}\) is proven for lower-\(\mathcal{C}^2\) functions in \cite{Hare2010}. This is not possible in the inexact case, even if the objective function \(f\) is convex.

To conclude this section we can say: At the moment there exist two fundamentally different approaches to tackle inexactness in various bundle methods depending on if the method is developed for convex or nonconvex objective functions.
In the nonconvex case inexactness is only considered in the paper by Hare, Sagastiz{\`{a}}bal and Sodolov \cite{Hare2016} presented above and Noll \cite{Noll2013}. In these cases the inexactness can be seen as an additional nonconvexity. In practice this means that the algorithm can be taken from the nonconvex case with no or only minor changes. This includes that all results of the exact case remain true as soon as function and subgradient are evaluated in an exact way.
In case of convex objective functions with inexact information stronger convergence results are possible. However to be able to exploit convexity in order to achieve those results the algorithms look different from those designed for nonconvex objective functions and are generally not able to deal with such functions. 

%changes in the algorithm are more involved. The reason for this is that generally stronger convergence results are possible with inexactness in the convex case than in the nonconvex case. %This means however, that the inexactness cannot be incorporated as easily into the algorithm

%\begin{itemize}
	%\item stronger convergence results possible because of exploitation of convexity
	%\item changes in the algorithm because if convexity should be exploited: inexactness cannot be treated as nonconvexity
	%\item 
%\end{itemize}

%\begin{itemize}
	%\item in paper other method for calculating \(\mu = \frac{1}{t_k}\) \\
	%\textcolor{red}{how is made sure that \(\eta\) big enough???}
	%\item convergence results for nonconvex functions:?
	%\begin{itemize}
		%\item conditions on functions: \\
		%\emph{exact}: \(f\) lower-\(\mathcal{C}^2\) near the minimizers of the problem \\
		%\emph{inexact}: proper, regular, locally Lipschitz with full domain; even better: lower-\(\mathcal{C}^1\) (contains lower-\(\mathcal{C}^2\)) \(\rightarrow\) conditions more general than in exact case
		%\item convergence results: \\
		%\emph{exact}: the limit of the sequence \(\{x^{k}\}\) (which exists) or every accumulation point of the sequence \(\{\hat{x}^k\}\) is a stationary point of \(f\)\\
		%\textcolor{red}{Does this mean: \(0 \in \partial f(\bar{x}), ~\bar{x}\) being the respective limit??? incorporate set \(D\)?} \\
		%\item \emph{inexact}: \(0 \in \left(\partial f(\bar{x}) + \partial I_D(\bar{x}) \right) + B_{\bar{\theta}}(0)\) \\
		%if \(f\) lower-\(\mathcal{C}^1\): 
		%\[ \forall \varepsilon >0 ~\exists \rho >0: \quad f(y) \geq f(\bar{x})-(\bar{\theta}+\varepsilon)\|y-\bar{x}\|-2\bar{\sigma} \quad \forall y \in D \cap B_{\rho}(\bar{x}) \]
%\end{itemize}

